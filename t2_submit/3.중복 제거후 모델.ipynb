{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6986d9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "🧹 1단계: 데이터 정제 (Flow-Packet 동기화 중복 제거)\n",
      "================================================================================\n",
      "📂 원본 데이터 로딩...\n",
      "✅ 원본 Flow/Packet 데이터 로딩 완료\n",
      "\n",
      "🔍 Flow 데이터 기준 중복 인덱스 식별...\n",
      "✅ 유효 인덱스 381,559개 확보 (제거될 중복: 218,441개)\n",
      "\n",
      "🔄 데이터 동기화 정제...\n",
      "✅ 동기화 완료! 최종 정제 데이터: 381,559개\n",
      "✅ 정제된 데이터 저장 완료\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================\n",
    "# 🚀 최종 마스터 파이프라인: 데이터 정제부터 모델 튜닝까지 한 번에!\n",
    "# ======================================================================\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import subprocess\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from catboost import CatBoostClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "try:\n",
    "    import optuna\n",
    "    OPTUNA_AVAILABLE = True\n",
    "except ImportError:\n",
    "    OPTUNA_AVAILABLE = False\n",
    "    \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# =======================================================\n",
    "# 🧹 1단계: 데이터 정제 (Flow-Packet 동기화 중복 제거)\n",
    "# =======================================================\n",
    "print(\"=\"*80)\n",
    "print(\"🧹 1단계: 데이터 정제 (Flow-Packet 동기화 중복 제거)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# --- 1-1: 원본 데이터 로딩 ---\n",
    "print(\"📂 원본 데이터 로딩...\")\n",
    "try:\n",
    "    flow_data_orig = joblib.load(\"task2_data/train_flow_data.pkl\")\n",
    "    # 🚨 중요: 이 단계는 메모리를 일시적으로 많이 사용할 수 있습니다. (대청소를 위한 일회성 투자)\n",
    "    all_packets_orig = []\n",
    "    packet_files = [f\"task2_data/train_packet_data_{i}.pkl\" for i in range(50000, 650000, 50000)]\n",
    "    for file_path in packet_files:\n",
    "        if os.path.exists(file_path):\n",
    "            packets_chunk = joblib.load(file_path)\n",
    "            all_packets_orig.extend(packets_chunk)\n",
    "    print(f\"✅ 원본 Flow/Packet 데이터 로딩 완료\")\n",
    "except FileNotFoundError:\n",
    "    print(\"❌ 원본 파일을 찾을 수 없습니다! 데이터 경로를 확인해주세요.\")\n",
    "    exit()\n",
    "\n",
    "# --- 1-2: Flow 데이터 기준 중복 인덱스 식별 ---\n",
    "print(\"\\n🔍 Flow 데이터 기준 중복 인덱스 식별...\")\n",
    "initial_rows = len(flow_data_orig)\n",
    "# .index를 통해 원본 인덱스를 그대로 보존하는 것이 핵심\n",
    "non_duplicate_indices = flow_data_orig.drop_duplicates().index\n",
    "final_rows = len(non_duplicate_indices)\n",
    "print(f\"✅ 유효 인덱스 {final_rows:,}개 확보 (제거될 중복: {initial_rows - final_rows:,}개)\")\n",
    "\n",
    "# --- 1-3: 유효 인덱스를 사용하여 데이터 동기화 정제 ---\n",
    "print(\"\\n🔄 데이터 동기화 정제...\")\n",
    "# Flow 데이터와 Packet 데이터를 동일한 순서로 재정렬하고, 인덱스를 0부터 새로 부여\n",
    "flow_data = flow_data_orig.loc[non_duplicate_indices].reset_index(drop=True)\n",
    "all_packets = [all_packets_orig[i] for i in non_duplicate_indices]\n",
    "print(f\"✅ 동기화 완료! 최종 정제 데이터: {len(flow_data):,}개\")\n",
    "# --- 1-4: 정제된 데이터 저장 ---\n",
    "joblib.dump(flow_data, \"task2_data/train_flow_data_cleaned.pkl\")\n",
    "joblib.dump(all_packets, \"task2_data/train_packet_data_cleaned.pkl\")\n",
    "print(\"✅ 정제된 데이터 저장 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54918ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "🎯 2단계: 대표 샘플 생성 (층화 추출)\n",
      "================================================================================\n",
      "🎯 목표 총 샘플 수: 100,000개\n",
      "✅ 샘플링 완료! 총 100,000개 대표 샘플 인덱스 확보.\n"
     ]
    }
   ],
   "source": [
    "# =======================================================\n",
    "# 🎯 2단계: 대표 샘플 생성 (층화 추출)\n",
    "# =======================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"🎯 2단계: 대표 샘플 생성 (층화 추출)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 👈 빠르고 간단한 테스트를 원하시면 이 숫자를 50000으로 줄이세요.\n",
    "target_total_samples = 100000  \n",
    "print(f\"🎯 목표 총 샘플 수: {target_total_samples:,}개\")\n",
    "\n",
    "# 복잡한 for 루프 없이, 전체 데이터에서 바로 샘플링\n",
    "stratify_key = flow_data['duration_class'].astype(str) + '_' + flow_data['volume_class'].astype(str)\n",
    "stratified_sampler = StratifiedShuffleSplit(n_splits=1, train_size=target_total_samples, random_state=42)\n",
    "indices = np.arange(len(flow_data))\n",
    "# sampled_indices는 이제 0부터 시작하는 '위치 인덱스'입니다.\n",
    "sampled_indices, _ = next(stratified_sampler.split(indices, stratify_key))\n",
    "print(f\"✅ 샘플링 완료! 총 {len(sampled_indices):,}개 대표 샘플 인덱스 확보.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b6b5605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "🔧 3단계: 고급 특징 엔지니어링\n",
      "================================================================================\n",
      "🚀 고급 특징 추출 시작...\n",
      "     진행률: 10,000 / 100,000개 완료\n",
      "     진행률: 20,000 / 100,000개 완료\n",
      "     진행률: 30,000 / 100,000개 완료\n",
      "     진행률: 40,000 / 100,000개 완료\n",
      "     진행률: 50,000 / 100,000개 완료\n",
      "     진행률: 60,000 / 100,000개 완료\n",
      "     진행률: 70,000 / 100,000개 완료\n",
      "     진행률: 80,000 / 100,000개 완료\n",
      "     진행률: 90,000 / 100,000개 완료\n",
      "     진행률: 100,000 / 100,000개 완료\n",
      "\n",
      "✅ 특징 추출 완료!\n",
      "✓ 최종 특징 행렬 크기: (100000, 44)\n",
      "✓ 최종 타겟 데이터 크기: (100000, 11)\n"
     ]
    }
   ],
   "source": [
    "# =======================================================\n",
    "# 🔧 3단계: 고급 특징 엔지니어링\n",
    "# =======================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"🔧 3단계: 고급 특징 엔지니어링\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def extract_packet_features(packets):\n",
    "    \"\"\" 패킷들로부터 고급 특징 추출 (최대 3개 패킷만 사용) \"\"\"\n",
    "    features = {}\n",
    "    num_packets = min(3, len(packets))\n",
    "    packets = packets.iloc[:num_packets]\n",
    "    \n",
    "    numeric_cols = packets.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        features[f'first_{col}'] = packets.iloc[0][col] if col in packets.columns else 0\n",
    "        features[f'second_{col}'] = packets.iloc[1][col] if col in packets.columns and len(packets) > 1 else 0\n",
    "    \n",
    "    if 'ip_len' in packets.columns:\n",
    "        ip_lens = packets['ip_len'].values\n",
    "        features['ip_len_mean_13'] = np.mean(ip_lens); features['ip_len_std_13'] = np.std(ip_lens) if len(ip_lens) > 1 else 0\n",
    "        features['ip_len_max_13'] = np.max(ip_lens); features['ip_len_min_13'] = np.min(ip_lens)\n",
    "        features['ip_len_range_13'] = np.max(ip_lens) - np.min(ip_lens); features['ip_len_median_13'] = np.median(ip_lens)\n",
    "        if len(ip_lens) >= 3:\n",
    "            diffs = np.diff(ip_lens)\n",
    "            features['ip_len_trend'] = 1 if np.mean(diffs) > 0 else (-1 if np.mean(diffs) < 0 else 0)\n",
    "            features['ip_len_volatility'] = np.std(diffs) if len(diffs) > 1 else 0\n",
    "        else:\n",
    "            features['ip_len_trend'] = 0; features['ip_len_volatility'] = 0\n",
    "    \n",
    "    if 'packet_capture_time' in packets.columns:\n",
    "        try:\n",
    "            times = pd.to_datetime(packets['packet_capture_time']); time_diffs = np.diff(times).astype('timedelta64[us]').astype(float)\n",
    "            if len(time_diffs) > 0:\n",
    "                features['inter_time_mean_13'] = np.mean(time_diffs); features['inter_time_std_13'] = np.std(time_diffs) if len(time_diffs) > 1 else 0\n",
    "                features['inter_time_max_13'] = np.max(time_diffs); features['inter_time_min_13'] = np.min(time_diffs)\n",
    "                features['timing_consistency'] = np.std(time_diffs) / (np.mean(time_diffs) + 1)\n",
    "            else:\n",
    "                for key in ['inter_time_mean_13', 'inter_time_std_13', 'inter_time_max_13', 'inter_time_min_13', 'timing_consistency']: features[key] = 0\n",
    "        except:\n",
    "            for key in ['inter_time_mean_13', 'inter_time_std_13', 'inter_time_max_13', 'inter_time_min_13', 'timing_consistency']: features[key] = 0\n",
    "    \n",
    "    if 'tcp_len' in packets.columns and 'ip_len' in packets.columns:\n",
    "        tcp_lens = packets['tcp_len'].values; features['tcp_len_mean_13'] = np.mean(tcp_lens)\n",
    "        features['tcp_len_std_13'] = np.std(tcp_lens) if len(tcp_lens) > 1 else 0; features['tcp_len_sum_13'] = np.sum(tcp_lens)\n",
    "        total_ip = np.sum(packets['ip_len']); total_tcp = np.sum(tcp_lens); features['tcp_efficiency_13'] = total_tcp / max(total_ip, 1)\n",
    "    \n",
    "    if 'tcp_flags' in packets.columns:\n",
    "        flags = packets['tcp_flags'].values\n",
    "        features['has_syn'] = int(any(flag & 0x02 for flag in flags)); features['has_ack'] = int(any(flag & 0x10 for flag in flags))\n",
    "        features['has_fin'] = int(any(flag & 0x01 for flag in flags)); features['has_rst'] = int(any(flag & 0x04 for flag in flags))\n",
    "        features['has_psh'] = int(any(flag & 0x08 for flag in flags))\n",
    "        if len(flags) >= 3:\n",
    "            first_syn = (flags[0] & 0x02) != 0; second_syn_ack = (flags[1] & 0x12) == 0x12; third_ack = (flags[2] & 0x10) != 0\n",
    "            features['is_handshake_complete'] = int(first_syn and second_syn_ack and third_ack)\n",
    "            has_fin_ack = any((flag & 0x11) == 0x11 for flag in flags); features['is_graceful_close'] = int(has_fin_ack)\n",
    "        else:\n",
    "            features['is_handshake_complete'] = 0; features['is_graceful_close'] = 0\n",
    "        features['flag_diversity'] = len(set(flags)); psh_count = sum(1 for flag in flags if flag & 0x08); features['push_frequency'] = psh_count / len(flags)\n",
    "    \n",
    "    if 'ip_len' in packets.columns and len(packets) >= 3:\n",
    "        sizes = packets['ip_len'].values; increases = sum(1 for i in range(1, len(sizes)) if sizes[i] > sizes[i-1]); decreases = sum(1 for i in range(1, len(sizes)) if sizes[i] < sizes[i-1])\n",
    "        features['size_increase_count'] = increases; features['size_decrease_count'] = decreases; features['size_stability'] = sum(1 for i in range(1, len(sizes)) if sizes[i] == sizes[i-1])\n",
    "    \n",
    "    if 'tcp_len' in packets.columns and 'ip_len' in packets.columns:\n",
    "        features['tcp_to_ip_ratio_first'] = packets.iloc[0]['tcp_len'] / max(packets.iloc[0]['ip_len'], 1)\n",
    "        if len(packets) > 1: features['tcp_to_ip_ratio_second'] = packets.iloc[1]['tcp_len'] / max(packets.iloc[1]['ip_len'], 1)\n",
    "    \n",
    "    features['inter_packet_time_us'] = features.get('inter_time_mean_13', 0); features['ip_len_diff'] = features.get('second_ip_len', 0) - features.get('first_ip_len', 0)\n",
    "    return features\n",
    "\n",
    "def extract_advanced_features_from_cleaned_data(indices, packet_data_list):\n",
    "    print(\"🚀 고급 특징 추출 시작...\")\n",
    "    features_list = []\n",
    "    for i, idx in enumerate(indices):\n",
    "        try:\n",
    "            packet_df = packet_data_list[idx]\n",
    "            if isinstance(packet_df, pd.DataFrame) and not packet_df.empty:\n",
    "                valid_packets = packet_df.dropna()\n",
    "                if len(valid_packets) >= 1:\n",
    "                    features = extract_packet_features(valid_packets)\n",
    "                    features_list.append(features)\n",
    "            if (i + 1) % 10000 == 0:\n",
    "                print(f\"     진행률: {i + 1:,} / {len(indices):,}개 완료\")\n",
    "        except Exception:\n",
    "            continue\n",
    "    return features_list\n",
    "\n",
    "advanced_features_list = extract_advanced_features_from_cleaned_data(sampled_indices, all_packets)\n",
    "advanced_features_df = pd.DataFrame(advanced_features_list).fillna(0)\n",
    "# iloc으로 샘플링된 flow 데이터를 가져오고, 인덱스를 리셋하여 특징 데이터와 완벽히 맞춤\n",
    "valid_flow_data = flow_data.iloc[sampled_indices].reset_index(drop=True)\n",
    "print(f\"\\n✅ 특징 추출 완료!\")\n",
    "print(f\"✓ 최종 특징 행렬 크기: {advanced_features_df.shape}\")\n",
    "print(f\"✓ 최종 타겟 데이터 크기: {valid_flow_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03943e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "🚀 4단계: 5개 모델 100회 하이퍼파라미터 튜닝\n",
      "================================================================================\n",
      "🔍 NVIDIA-SMI: ✅ 감지됨\n",
      "🔍 CatBoost 버전: 1.2.8\n",
      "🔍 CatBoost GPU: ✅ 작동 확인\n",
      "🔍 XGBoost 버전: 3.0.2\n",
      "🔍 XGBoost GPU: ✅ 작동 확인\n",
      "🔍 LightGBM 버전: 4.6.0\n",
      "🔍 LightGBM GPU: ✅ 작동 확인\n",
      "🖥️ GPU 상태: NVIDIA ✅ | CatBoost ✅ | XGBoost ✅ | LightGBM ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 00:57:03,797] A new study created in memory with name: no-name-41a42d4d-fc8d-4029-b987-f7ad9c4856c4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 데이터 준비: 학습 80,000개 | 검증 20,000개 | 특징 44개\n",
      "⚖️ 클래스 가중치 계산 완료\n",
      "\n",
      "--- CatBoost 튜닝 시작 ---\n",
      "🎯 CatBoost - Duration 분류 튜닝...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "128d5eeea1464babb7dedd6a933a8807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    🖥️ CatBoost GPU 모드로 실행\n",
      "[I 2025-08-08 00:57:09,505] Trial 0 finished with value: 0.723792040542015 and parameters: {'iterations': 400, 'depth': 6, 'learning_rate': 0.03, 'l2_leaf_reg': 5, 'border_count': 128}. Best is trial 0 with value: 0.723792040542015.\n",
      "[I 2025-08-08 00:58:03,978] Trial 1 finished with value: 0.7428328444289712 and parameters: {'iterations': 600, 'depth': 10, 'learning_rate': 0.1, 'l2_leaf_reg': 3, 'border_count': 128}. Best is trial 1 with value: 0.7428328444289712.\n",
      "[I 2025-08-08 00:58:09,420] Trial 2 finished with value: 0.7323445701079838 and parameters: {'iterations': 200, 'depth': 8, 'learning_rate': 0.05, 'l2_leaf_reg': 5, 'border_count': 128}. Best is trial 1 with value: 0.7428328444289712.\n",
      "[I 2025-08-08 00:58:37,811] Trial 3 finished with value: 0.7318817045089978 and parameters: {'iterations': 200, 'depth': 10, 'learning_rate': 0.03, 'l2_leaf_reg': 3, 'border_count': 254}. Best is trial 1 with value: 0.7428328444289712.\n",
      "[I 2025-08-08 00:59:30,962] Trial 4 finished with value: 0.7428328444289712 and parameters: {'iterations': 600, 'depth': 10, 'learning_rate': 0.1, 'l2_leaf_reg': 3, 'border_count': 128}. Best is trial 1 with value: 0.7428328444289712.\n",
      "[I 2025-08-08 01:00:01,065] Trial 5 finished with value: 0.7397368044443408 and parameters: {'iterations': 400, 'depth': 10, 'learning_rate': 0.03, 'l2_leaf_reg': 5, 'border_count': 128}. Best is trial 1 with value: 0.7428328444289712.\n",
      "[I 2025-08-08 01:00:20,655] Trial 6 finished with value: 0.7401787717905042 and parameters: {'iterations': 600, 'depth': 8, 'learning_rate': 0.03, 'l2_leaf_reg': 5, 'border_count': 254}. Best is trial 1 with value: 0.7428328444289712.\n",
      "[I 2025-08-08 01:00:59,011] Trial 7 finished with value: 0.7447218448036881 and parameters: {'iterations': 600, 'depth': 10, 'learning_rate': 0.03, 'l2_leaf_reg': 3, 'border_count': 128}. Best is trial 7 with value: 0.7447218448036881.\n",
      "[I 2025-08-08 01:02:48,286] Trial 8 finished with value: 0.7425524443157968 and parameters: {'iterations': 400, 'depth': 12, 'learning_rate': 0.03, 'l2_leaf_reg': 3, 'border_count': 254}. Best is trial 7 with value: 0.7447218448036881.\n",
      "[I 2025-08-08 01:03:08,094] Trial 9 finished with value: 0.7401296456122836 and parameters: {'iterations': 600, 'depth': 8, 'learning_rate': 0.03, 'l2_leaf_reg': 5, 'border_count': 254}. Best is trial 7 with value: 0.7447218448036881.\n",
      "[I 2025-08-08 01:03:16,785] Trial 10 finished with value: 0.7396166207278557 and parameters: {'iterations': 600, 'depth': 6, 'learning_rate': 0.05, 'l2_leaf_reg': 7, 'border_count': 128}. Best is trial 7 with value: 0.7447218448036881.\n",
      "[I 2025-08-08 01:03:56,214] Trial 11 finished with value: 0.7428328444289712 and parameters: {'iterations': 600, 'depth': 10, 'learning_rate': 0.1, 'l2_leaf_reg': 3, 'border_count': 128}. Best is trial 7 with value: 0.7447218448036881.\n",
      "[I 2025-08-08 01:04:35,508] Trial 12 finished with value: 0.7428328444289712 and parameters: {'iterations': 600, 'depth': 10, 'learning_rate': 0.1, 'l2_leaf_reg': 3, 'border_count': 128}. Best is trial 7 with value: 0.7447218448036881.\n",
      "[I 2025-08-08 01:06:36,620] Trial 13 finished with value: 0.740793145359438 and parameters: {'iterations': 600, 'depth': 12, 'learning_rate': 0.1, 'l2_leaf_reg': 7, 'border_count': 128}. Best is trial 7 with value: 0.7447218448036881.\n",
      "[I 2025-08-08 01:07:15,381] Trial 14 finished with value: 0.7428328444289712 and parameters: {'iterations': 600, 'depth': 10, 'learning_rate': 0.1, 'l2_leaf_reg': 3, 'border_count': 128}. Best is trial 7 with value: 0.7447218448036881.\n",
      "[I 2025-08-08 01:07:28,203] Trial 15 finished with value: 0.7387819401258539 and parameters: {'iterations': 200, 'depth': 10, 'learning_rate': 0.05, 'l2_leaf_reg': 3, 'border_count': 128}. Best is trial 7 with value: 0.7447218448036881.\n",
      "[I 2025-08-08 01:08:06,988] Trial 16 finished with value: 0.7428328444289712 and parameters: {'iterations': 600, 'depth': 10, 'learning_rate': 0.1, 'l2_leaf_reg': 3, 'border_count': 128}. Best is trial 7 with value: 0.7447218448036881.\n",
      "[I 2025-08-08 01:08:15,156] Trial 17 finished with value: 0.7446733303204313 and parameters: {'iterations': 600, 'depth': 6, 'learning_rate': 0.1, 'l2_leaf_reg': 7, 'border_count': 128}. Best is trial 7 with value: 0.7447218448036881.\n",
      "[I 2025-08-08 01:08:18,724] Trial 18 finished with value: 0.7030472239390191 and parameters: {'iterations': 200, 'depth': 6, 'learning_rate': 0.03, 'l2_leaf_reg': 7, 'border_count': 254}. Best is trial 7 with value: 0.7447218448036881.\n",
      "[I 2025-08-08 01:08:24,319] Trial 19 finished with value: 0.7339726988042038 and parameters: {'iterations': 400, 'depth': 6, 'learning_rate': 0.05, 'l2_leaf_reg': 7, 'border_count': 128}. Best is trial 7 with value: 0.7447218448036881.\n",
      "[I 2025-08-08 01:08:32,375] Trial 20 finished with value: 0.7446733303204313 and parameters: {'iterations': 600, 'depth': 6, 'learning_rate': 0.1, 'l2_leaf_reg': 7, 'border_count': 128}. Best is trial 7 with value: 0.7447218448036881.\n",
      "[I 2025-08-08 01:08:40,490] Trial 21 finished with value: 0.7446733303204313 and parameters: {'iterations': 600, 'depth': 6, 'learning_rate': 0.1, 'l2_leaf_reg': 7, 'border_count': 128}. Best is trial 7 with value: 0.7447218448036881.\n",
      "[I 2025-08-08 01:08:48,593] Trial 22 finished with value: 0.7446733303204313 and parameters: {'iterations': 600, 'depth': 6, 'learning_rate': 0.1, 'l2_leaf_reg': 7, 'border_count': 128}. Best is trial 7 with value: 0.7447218448036881.\n",
      "[I 2025-08-08 01:08:56,708] Trial 23 finished with value: 0.7446733303204313 and parameters: {'iterations': 600, 'depth': 6, 'learning_rate': 0.1, 'l2_leaf_reg': 7, 'border_count': 128}. Best is trial 7 with value: 0.7447218448036881.\n",
      "[I 2025-08-08 01:09:04,780] Trial 24 finished with value: 0.7446733303204313 and parameters: {'iterations': 600, 'depth': 6, 'learning_rate': 0.1, 'l2_leaf_reg': 7, 'border_count': 128}. Best is trial 7 with value: 0.7447218448036881.\n",
      "[I 2025-08-08 01:11:04,262] Trial 25 finished with value: 0.7422030874670655 and parameters: {'iterations': 600, 'depth': 12, 'learning_rate': 0.03, 'l2_leaf_reg': 7, 'border_count': 128}. Best is trial 7 with value: 0.7447218448036881.\n",
      "[I 2025-08-08 01:11:14,341] Trial 26 finished with value: 0.7436097030966815 and parameters: {'iterations': 600, 'depth': 6, 'learning_rate': 0.1, 'l2_leaf_reg': 7, 'border_count': 254}. Best is trial 7 with value: 0.7447218448036881.\n",
      "[I 2025-08-08 01:11:22,762] Trial 27 finished with value: 0.7446733303204313 and parameters: {'iterations': 600, 'depth': 6, 'learning_rate': 0.1, 'l2_leaf_reg': 7, 'border_count': 128}. Best is trial 7 with value: 0.7447218448036881.\n",
      "[I 2025-08-08 01:12:41,934] Trial 28 finished with value: 0.7430590345754301 and parameters: {'iterations': 400, 'depth': 12, 'learning_rate': 0.05, 'l2_leaf_reg': 7, 'border_count': 128}. Best is trial 7 with value: 0.7447218448036881.\n",
      "[I 2025-08-08 01:12:45,015] Trial 29 finished with value: 0.7023023365202001 and parameters: {'iterations': 200, 'depth': 6, 'learning_rate': 0.03, 'l2_leaf_reg': 7, 'border_count': 128}. Best is trial 7 with value: 0.7447218448036881.\n",
      "    ✅ 최적 CatBoost 모델 GPU 모드로 학습 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 01:12:57,981] A new study created in memory with name: no-name-a065a697-cc61-4e97-95a6-ca3f2dc5c73c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > 최종 검증 F1(weighted): 0.7365\n",
      "📦 CatBoost - Volume 분류 튜닝...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52c75005d25f4497afe12690747d1dd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    🖥️ CatBoost GPU 모드로 실행\n",
      "[I 2025-08-08 01:13:03,536] Trial 0 finished with value: 0.27950702747130424 and parameters: {'iterations': 400, 'depth': 6, 'learning_rate': 0.03, 'l2_leaf_reg': 5, 'border_count': 128}. Best is trial 0 with value: 0.27950702747130424.\n",
      "[I 2025-08-08 01:13:44,126] Trial 1 finished with value: 0.30851405916522756 and parameters: {'iterations': 600, 'depth': 10, 'learning_rate': 0.1, 'l2_leaf_reg': 3, 'border_count': 128}. Best is trial 1 with value: 0.30851405916522756.\n",
      "[I 2025-08-08 01:13:49,650] Trial 2 finished with value: 0.28307999137592055 and parameters: {'iterations': 200, 'depth': 8, 'learning_rate': 0.05, 'l2_leaf_reg': 5, 'border_count': 128}. Best is trial 1 with value: 0.30851405916522756.\n",
      "[I 2025-08-08 01:14:08,510] Trial 3 finished with value: 0.2834522906767665 and parameters: {'iterations': 200, 'depth': 10, 'learning_rate': 0.03, 'l2_leaf_reg': 3, 'border_count': 254}. Best is trial 1 with value: 0.30851405916522756.\n",
      "[I 2025-08-08 01:15:05,101] Trial 4 finished with value: 0.30851405916522756 and parameters: {'iterations': 600, 'depth': 10, 'learning_rate': 0.1, 'l2_leaf_reg': 3, 'border_count': 128}. Best is trial 1 with value: 0.30851405916522756.\n",
      "[I 2025-08-08 01:15:31,794] Trial 5 finished with value: 0.2899175821341322 and parameters: {'iterations': 400, 'depth': 10, 'learning_rate': 0.03, 'l2_leaf_reg': 5, 'border_count': 128}. Best is trial 1 with value: 0.30851405916522756.\n",
      "[I 2025-08-08 01:15:51,538] Trial 6 finished with value: 0.2856633951074347 and parameters: {'iterations': 600, 'depth': 8, 'learning_rate': 0.03, 'l2_leaf_reg': 5, 'border_count': 254}. Best is trial 1 with value: 0.30851405916522756.\n",
      "[I 2025-08-08 01:16:31,683] Trial 7 finished with value: 0.29496911293140576 and parameters: {'iterations': 600, 'depth': 10, 'learning_rate': 0.03, 'l2_leaf_reg': 3, 'border_count': 128}. Best is trial 1 with value: 0.30851405916522756.\n",
      "[I 2025-08-08 01:18:27,572] Trial 8 finished with value: 0.29609103660578534 and parameters: {'iterations': 400, 'depth': 12, 'learning_rate': 0.03, 'l2_leaf_reg': 3, 'border_count': 254}. Best is trial 1 with value: 0.30851405916522756.\n",
      "[I 2025-08-08 01:18:47,304] Trial 9 finished with value: 0.28508938602985795 and parameters: {'iterations': 600, 'depth': 8, 'learning_rate': 0.03, 'l2_leaf_reg': 5, 'border_count': 254}. Best is trial 1 with value: 0.30851405916522756.\n",
      "[I 2025-08-08 01:18:55,432] Trial 10 finished with value: 0.29192643731685036 and parameters: {'iterations': 600, 'depth': 6, 'learning_rate': 0.1, 'l2_leaf_reg': 7, 'border_count': 128}. Best is trial 1 with value: 0.30851405916522756.\n",
      "[I 2025-08-08 01:19:35,530] Trial 11 finished with value: 0.3078828356433923 and parameters: {'iterations': 600, 'depth': 10, 'learning_rate': 0.1, 'l2_leaf_reg': 3, 'border_count': 128}. Best is trial 1 with value: 0.30851405916522756.\n",
      "[I 2025-08-08 01:20:15,892] Trial 12 finished with value: 0.307882898021455 and parameters: {'iterations': 600, 'depth': 10, 'learning_rate': 0.1, 'l2_leaf_reg': 3, 'border_count': 128}. Best is trial 1 with value: 0.30851405916522756.\n",
      "[I 2025-08-08 01:22:32,465] Trial 13 finished with value: 0.30872111509119743 and parameters: {'iterations': 600, 'depth': 12, 'learning_rate': 0.1, 'l2_leaf_reg': 7, 'border_count': 128}. Best is trial 13 with value: 0.30872111509119743.\n",
      "[I 2025-08-08 01:24:38,348] Trial 14 finished with value: 0.30872111509119743 and parameters: {'iterations': 600, 'depth': 12, 'learning_rate': 0.1, 'l2_leaf_reg': 7, 'border_count': 128}. Best is trial 13 with value: 0.30872111509119743.\n",
      "[I 2025-08-08 01:25:22,328] Trial 15 finished with value: 0.2917396695066958 and parameters: {'iterations': 200, 'depth': 12, 'learning_rate': 0.05, 'l2_leaf_reg': 7, 'border_count': 128}. Best is trial 13 with value: 0.30872111509119743.\n",
      "[I 2025-08-08 01:28:06,522] Trial 16 finished with value: 0.30872111509119743 and parameters: {'iterations': 600, 'depth': 12, 'learning_rate': 0.1, 'l2_leaf_reg': 7, 'border_count': 128}. Best is trial 13 with value: 0.30872111509119743.\n",
      "[I 2025-08-08 01:31:26,921] Trial 17 finished with value: 0.30872111509119743 and parameters: {'iterations': 600, 'depth': 12, 'learning_rate': 0.1, 'l2_leaf_reg': 7, 'border_count': 128}. Best is trial 13 with value: 0.30872111509119743.\n",
      "[I 2025-08-08 01:33:03,904] Trial 18 finished with value: 0.30148206619520246 and parameters: {'iterations': 200, 'depth': 12, 'learning_rate': 0.1, 'l2_leaf_reg': 7, 'border_count': 254}. Best is trial 13 with value: 0.30872111509119743.\n",
      "[I 2025-08-08 01:35:42,065] Trial 19 finished with value: 0.30060444926814817 and parameters: {'iterations': 400, 'depth': 12, 'learning_rate': 0.05, 'l2_leaf_reg': 7, 'border_count': 128}. Best is trial 13 with value: 0.30872111509119743.\n",
      "[I 2025-08-08 01:38:45,116] Trial 20 finished with value: 0.30872111509119743 and parameters: {'iterations': 600, 'depth': 12, 'learning_rate': 0.1, 'l2_leaf_reg': 7, 'border_count': 128}. Best is trial 13 with value: 0.30872111509119743.\n",
      "[I 2025-08-08 01:40:51,214] Trial 21 finished with value: 0.30872111509119743 and parameters: {'iterations': 600, 'depth': 12, 'learning_rate': 0.1, 'l2_leaf_reg': 7, 'border_count': 128}. Best is trial 13 with value: 0.30872111509119743.\n",
      "[I 2025-08-08 01:42:57,674] Trial 22 finished with value: 0.30872111509119743 and parameters: {'iterations': 600, 'depth': 12, 'learning_rate': 0.1, 'l2_leaf_reg': 7, 'border_count': 128}. Best is trial 13 with value: 0.30872111509119743.\n",
      "[I 2025-08-08 01:45:03,859] Trial 23 finished with value: 0.30872111509119743 and parameters: {'iterations': 600, 'depth': 12, 'learning_rate': 0.1, 'l2_leaf_reg': 7, 'border_count': 128}. Best is trial 13 with value: 0.30872111509119743.\n",
      "[I 2025-08-08 01:47:09,720] Trial 24 finished with value: 0.30872111509119743 and parameters: {'iterations': 600, 'depth': 12, 'learning_rate': 0.1, 'l2_leaf_reg': 7, 'border_count': 128}. Best is trial 13 with value: 0.30872111509119743.\n",
      "[I 2025-08-08 01:47:18,128] Trial 25 finished with value: 0.29192643731685036 and parameters: {'iterations': 600, 'depth': 6, 'learning_rate': 0.1, 'l2_leaf_reg': 7, 'border_count': 128}. Best is trial 13 with value: 0.30872111509119743.\n",
      "[I 2025-08-08 01:50:12,161] Trial 26 finished with value: 0.30247043072403085 and parameters: {'iterations': 600, 'depth': 12, 'learning_rate': 0.05, 'l2_leaf_reg': 7, 'border_count': 254}. Best is trial 13 with value: 0.30872111509119743.\n",
      "[I 2025-08-08 01:52:17,697] Trial 27 finished with value: 0.30872111509119743 and parameters: {'iterations': 600, 'depth': 12, 'learning_rate': 0.1, 'l2_leaf_reg': 7, 'border_count': 128}. Best is trial 13 with value: 0.30872111509119743.\n",
      "[I 2025-08-08 01:53:41,847] Trial 28 finished with value: 0.30783197131312184 and parameters: {'iterations': 400, 'depth': 12, 'learning_rate': 0.1, 'l2_leaf_reg': 7, 'border_count': 128}. Best is trial 13 with value: 0.30872111509119743.\n",
      "[I 2025-08-08 01:53:44,942] Trial 29 finished with value: 0.2854077812674329 and parameters: {'iterations': 200, 'depth': 6, 'learning_rate': 0.1, 'l2_leaf_reg': 7, 'border_count': 128}. Best is trial 13 with value: 0.30872111509119743.\n",
      "    ✅ 최적 CatBoost 모델 GPU 모드로 학습 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 01:54:27,991] A new study created in memory with name: no-name-8abc749e-7171-4c69-9a22-ffd1836d6305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > 최종 검증 F1(weighted): 0.2892\n",
      "\n",
      "--- XGBoost 튜닝 시작 ---\n",
      "🎯 XGBoost - Duration 분류 튜닝...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab2042c179c144d7bb8372786c89434a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    🖥️ XGBoost GPU(gpu_hist) 모드로 실행\n",
      "[I 2025-08-08 01:54:39,935] Trial 0 finished with value: 0.7423599178402891 and parameters: {'n_estimators': 400, 'max_depth': 6, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8}. Best is trial 0 with value: 0.7423599178402891.\n",
      "[I 2025-08-08 01:54:49,572] Trial 1 finished with value: 0.7428363892173658 and parameters: {'n_estimators': 200, 'max_depth': 8, 'learning_rate': 0.05, 'subsample': 0.9, 'colsample_bytree': 0.9}. Best is trial 1 with value: 0.7428363892173658.\n",
      "[I 2025-08-08 01:55:22,204] Trial 2 finished with value: 0.7388657451858998 and parameters: {'n_estimators': 600, 'max_depth': 8, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.9}. Best is trial 1 with value: 0.7428363892173658.\n",
      "[I 2025-08-08 01:55:51,913] Trial 3 finished with value: 0.7465722160656864 and parameters: {'n_estimators': 600, 'max_depth': 8, 'learning_rate': 0.03, 'subsample': 0.8, 'colsample_bytree': 0.8}. Best is trial 3 with value: 0.7465722160656864.\n",
      "[I 2025-08-08 01:55:58,159] Trial 4 finished with value: 0.7418165418681232 and parameters: {'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.1, 'subsample': 0.9, 'colsample_bytree': 0.8}. Best is trial 3 with value: 0.7465722160656864.\n",
      "[I 2025-08-08 01:56:29,170] Trial 5 finished with value: 0.7428261432773932 and parameters: {'n_estimators': 600, 'max_depth': 8, 'learning_rate': 0.1, 'subsample': 0.9, 'colsample_bytree': 0.8}. Best is trial 3 with value: 0.7465722160656864.\n",
      "[I 2025-08-08 01:57:03,956] Trial 6 finished with value: 0.7445078379419607 and parameters: {'n_estimators': 600, 'max_depth': 6, 'learning_rate': 0.1, 'subsample': 0.9, 'colsample_bytree': 0.8}. Best is trial 3 with value: 0.7465722160656864.\n",
      "[I 2025-08-08 01:57:15,685] Trial 7 finished with value: 0.7329872460880996 and parameters: {'n_estimators': 400, 'max_depth': 6, 'learning_rate': 0.03, 'subsample': 0.9, 'colsample_bytree': 0.9}. Best is trial 3 with value: 0.7465722160656864.\n",
      "[I 2025-08-08 01:57:22,019] Trial 8 finished with value: 0.7409707887375236 and parameters: {'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8}. Best is trial 3 with value: 0.7465722160656864.\n",
      "[I 2025-08-08 01:57:43,013] Trial 9 finished with value: 0.7452269348265307 and parameters: {'n_estimators': 400, 'max_depth': 8, 'learning_rate': 0.1, 'subsample': 0.9, 'colsample_bytree': 0.9}. Best is trial 3 with value: 0.7465722160656864.\n",
      "[I 2025-08-08 01:58:33,773] Trial 10 finished with value: 0.7470071103419015 and parameters: {'n_estimators': 600, 'max_depth': 10, 'learning_rate': 0.03, 'subsample': 0.8, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.7470071103419015.\n",
      "[I 2025-08-08 01:59:24,705] Trial 11 finished with value: 0.7470071103419015 and parameters: {'n_estimators': 600, 'max_depth': 10, 'learning_rate': 0.03, 'subsample': 0.8, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.7470071103419015.\n",
      "[I 2025-08-08 02:00:15,555] Trial 12 finished with value: 0.7470071103419015 and parameters: {'n_estimators': 600, 'max_depth': 10, 'learning_rate': 0.03, 'subsample': 0.8, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.7470071103419015.\n",
      "[I 2025-08-08 02:01:06,279] Trial 13 finished with value: 0.7470071103419015 and parameters: {'n_estimators': 600, 'max_depth': 10, 'learning_rate': 0.03, 'subsample': 0.8, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.7470071103419015.\n",
      "[I 2025-08-08 02:01:56,992] Trial 14 finished with value: 0.7470071103419015 and parameters: {'n_estimators': 600, 'max_depth': 10, 'learning_rate': 0.03, 'subsample': 0.8, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.7470071103419015.\n",
      "[I 2025-08-08 02:02:47,386] Trial 15 finished with value: 0.7470071103419015 and parameters: {'n_estimators': 600, 'max_depth': 10, 'learning_rate': 0.03, 'subsample': 0.8, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.7470071103419015.\n",
      "[I 2025-08-08 02:03:37,736] Trial 16 finished with value: 0.7470071103419015 and parameters: {'n_estimators': 600, 'max_depth': 10, 'learning_rate': 0.03, 'subsample': 0.8, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.7470071103419015.\n",
      "[I 2025-08-08 02:04:27,977] Trial 17 finished with value: 0.7470071103419015 and parameters: {'n_estimators': 600, 'max_depth': 10, 'learning_rate': 0.03, 'subsample': 0.8, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.7470071103419015.\n",
      "[I 2025-08-08 02:04:44,383] Trial 18 finished with value: 0.7467679889405092 and parameters: {'n_estimators': 200, 'max_depth': 10, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.7470071103419015.\n",
      "[I 2025-08-08 02:05:16,485] Trial 19 finished with value: 0.747744586489528 and parameters: {'n_estimators': 400, 'max_depth': 10, 'learning_rate': 0.03, 'subsample': 0.8, 'colsample_bytree': 0.8}. Best is trial 19 with value: 0.747744586489528.\n",
      "[I 2025-08-08 02:05:48,585] Trial 20 finished with value: 0.747744586489528 and parameters: {'n_estimators': 400, 'max_depth': 10, 'learning_rate': 0.03, 'subsample': 0.8, 'colsample_bytree': 0.8}. Best is trial 19 with value: 0.747744586489528.\n",
      "[I 2025-08-08 02:06:20,872] Trial 21 finished with value: 0.747744586489528 and parameters: {'n_estimators': 400, 'max_depth': 10, 'learning_rate': 0.03, 'subsample': 0.8, 'colsample_bytree': 0.8}. Best is trial 19 with value: 0.747744586489528.\n",
      "[I 2025-08-08 02:06:53,031] Trial 22 finished with value: 0.747744586489528 and parameters: {'n_estimators': 400, 'max_depth': 10, 'learning_rate': 0.03, 'subsample': 0.8, 'colsample_bytree': 0.8}. Best is trial 19 with value: 0.747744586489528.\n",
      "[I 2025-08-08 02:07:25,125] Trial 23 finished with value: 0.747744586489528 and parameters: {'n_estimators': 400, 'max_depth': 10, 'learning_rate': 0.03, 'subsample': 0.8, 'colsample_bytree': 0.8}. Best is trial 19 with value: 0.747744586489528.\n",
      "[I 2025-08-08 02:07:57,339] Trial 24 finished with value: 0.747744586489528 and parameters: {'n_estimators': 400, 'max_depth': 10, 'learning_rate': 0.03, 'subsample': 0.8, 'colsample_bytree': 0.8}. Best is trial 19 with value: 0.747744586489528.\n",
      "[I 2025-08-08 02:08:31,397] Trial 25 finished with value: 0.7445292244701559 and parameters: {'n_estimators': 400, 'max_depth': 10, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8}. Best is trial 19 with value: 0.747744586489528.\n",
      "[I 2025-08-08 02:09:04,271] Trial 26 finished with value: 0.7462953529108391 and parameters: {'n_estimators': 400, 'max_depth': 10, 'learning_rate': 0.03, 'subsample': 0.8, 'colsample_bytree': 0.9}. Best is trial 19 with value: 0.747744586489528.\n",
      "[I 2025-08-08 02:09:36,293] Trial 27 finished with value: 0.747744586489528 and parameters: {'n_estimators': 400, 'max_depth': 10, 'learning_rate': 0.03, 'subsample': 0.8, 'colsample_bytree': 0.8}. Best is trial 19 with value: 0.747744586489528.\n",
      "[I 2025-08-08 02:10:08,698] Trial 28 finished with value: 0.747744586489528 and parameters: {'n_estimators': 400, 'max_depth': 10, 'learning_rate': 0.03, 'subsample': 0.8, 'colsample_bytree': 0.8}. Best is trial 19 with value: 0.747744586489528.\n",
      "[I 2025-08-08 02:10:43,788] Trial 29 finished with value: 0.7445292244701559 and parameters: {'n_estimators': 400, 'max_depth': 10, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8}. Best is trial 19 with value: 0.747744586489528.\n",
      "    ✅ 최적 XGBoost 모델 GPU(gpu_hist) 모드로 학습 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 02:10:56,248] A new study created in memory with name: no-name-2f2a7d5d-02ae-4b73-b959-5f17fc51d7e5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > 최종 검증 F1(weighted): 0.7476\n",
      "📦 XGBoost - Volume 분류 튜닝...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea827485d1c647c2b14a041c54744e11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    🖥️ XGBoost GPU(gpu_hist) 모드로 실행\n",
      "[I 2025-08-08 02:11:09,398] Trial 0 finished with value: 0.2817110886727891 and parameters: {'n_estimators': 400, 'max_depth': 6, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8}. Best is trial 0 with value: 0.2817110886727891.\n",
      "[I 2025-08-08 02:11:21,767] Trial 1 finished with value: 0.288779443450038 and parameters: {'n_estimators': 200, 'max_depth': 8, 'learning_rate': 0.05, 'subsample': 0.9, 'colsample_bytree': 0.9}. Best is trial 1 with value: 0.288779443450038.\n",
      "[I 2025-08-08 02:11:59,225] Trial 2 finished with value: 0.3097595480466848 and parameters: {'n_estimators': 600, 'max_depth': 8, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.9}. Best is trial 2 with value: 0.3097595480466848.\n",
      "[I 2025-08-08 02:12:34,950] Trial 3 finished with value: 0.29848980151380383 and parameters: {'n_estimators': 600, 'max_depth': 8, 'learning_rate': 0.03, 'subsample': 0.8, 'colsample_bytree': 0.8}. Best is trial 2 with value: 0.3097595480466848.\n",
      "[I 2025-08-08 02:12:41,666] Trial 4 finished with value: 0.2823082300011798 and parameters: {'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.1, 'subsample': 0.9, 'colsample_bytree': 0.8}. Best is trial 2 with value: 0.3097595480466848.\n",
      "[I 2025-08-08 02:13:16,326] Trial 5 finished with value: 0.30783261826036595 and parameters: {'n_estimators': 600, 'max_depth': 8, 'learning_rate': 0.1, 'subsample': 0.9, 'colsample_bytree': 0.8}. Best is trial 2 with value: 0.3097595480466848.\n",
      "[I 2025-08-08 02:13:35,084] Trial 6 finished with value: 0.2980647979602365 and parameters: {'n_estimators': 600, 'max_depth': 6, 'learning_rate': 0.1, 'subsample': 0.9, 'colsample_bytree': 0.8}. Best is trial 2 with value: 0.3097595480466848.\n",
      "[I 2025-08-08 02:13:47,897] Trial 7 finished with value: 0.27514249214274195 and parameters: {'n_estimators': 400, 'max_depth': 6, 'learning_rate': 0.03, 'subsample': 0.9, 'colsample_bytree': 0.9}. Best is trial 2 with value: 0.3097595480466848.\n",
      "[I 2025-08-08 02:13:54,649] Trial 8 finished with value: 0.2805475835501614 and parameters: {'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8}. Best is trial 2 with value: 0.3097595480466848.\n",
      "[I 2025-08-08 02:14:18,743] Trial 9 finished with value: 0.3057680218554802 and parameters: {'n_estimators': 400, 'max_depth': 8, 'learning_rate': 0.1, 'subsample': 0.9, 'colsample_bytree': 0.9}. Best is trial 2 with value: 0.3097595480466848.\n",
      "[I 2025-08-08 02:15:30,011] Trial 10 finished with value: 0.3098630992712667 and parameters: {'n_estimators': 600, 'max_depth': 10, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.3098630992712667.\n",
      "[I 2025-08-08 02:16:40,618] Trial 11 finished with value: 0.3098630992712667 and parameters: {'n_estimators': 600, 'max_depth': 10, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.3098630992712667.\n",
      "[I 2025-08-08 02:17:50,712] Trial 12 finished with value: 0.3098630992712667 and parameters: {'n_estimators': 600, 'max_depth': 10, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.3098630992712667.\n",
      "[I 2025-08-08 02:19:01,424] Trial 13 finished with value: 0.3098630992712667 and parameters: {'n_estimators': 600, 'max_depth': 10, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.3098630992712667.\n",
      "[I 2025-08-08 02:20:12,435] Trial 14 finished with value: 0.3098630992712667 and parameters: {'n_estimators': 600, 'max_depth': 10, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.3098630992712667.\n",
      "[I 2025-08-08 02:21:23,370] Trial 15 finished with value: 0.3098630992712667 and parameters: {'n_estimators': 600, 'max_depth': 10, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.3098630992712667.\n",
      "[I 2025-08-08 02:22:34,108] Trial 16 finished with value: 0.3098630992712667 and parameters: {'n_estimators': 600, 'max_depth': 10, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.3098630992712667.\n",
      "[I 2025-08-08 02:23:45,092] Trial 17 finished with value: 0.3098630992712667 and parameters: {'n_estimators': 600, 'max_depth': 10, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.3098630992712667.\n",
      "[I 2025-08-08 02:24:08,538] Trial 18 finished with value: 0.296351396978816 and parameters: {'n_estimators': 200, 'max_depth': 10, 'learning_rate': 0.03, 'subsample': 0.8, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.3098630992712667.\n",
      "[I 2025-08-08 02:24:55,293] Trial 19 finished with value: 0.30888688620653143 and parameters: {'n_estimators': 400, 'max_depth': 10, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.3098630992712667.\n",
      "[I 2025-08-08 02:26:04,014] Trial 20 finished with value: 0.3098630992712667 and parameters: {'n_estimators': 600, 'max_depth': 10, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.3098630992712667.\n",
      "[I 2025-08-08 02:27:14,670] Trial 21 finished with value: 0.3098630992712667 and parameters: {'n_estimators': 600, 'max_depth': 10, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.3098630992712667.\n",
      "[I 2025-08-08 02:28:26,449] Trial 22 finished with value: 0.3098630992712667 and parameters: {'n_estimators': 600, 'max_depth': 10, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.3098630992712667.\n",
      "[I 2025-08-08 02:29:37,491] Trial 23 finished with value: 0.3098630992712667 and parameters: {'n_estimators': 600, 'max_depth': 10, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.3098630992712667.\n",
      "[I 2025-08-08 02:30:48,614] Trial 24 finished with value: 0.3098630992712667 and parameters: {'n_estimators': 600, 'max_depth': 10, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.3098630992712667.\n",
      "[I 2025-08-08 02:31:59,463] Trial 25 finished with value: 0.3086410695131007 and parameters: {'n_estimators': 600, 'max_depth': 10, 'learning_rate': 0.03, 'subsample': 0.8, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.3098630992712667.\n",
      "[I 2025-08-08 02:33:10,436] Trial 26 finished with value: 0.3098630992712667 and parameters: {'n_estimators': 600, 'max_depth': 10, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.3098630992712667.\n",
      "[I 2025-08-08 02:34:19,805] Trial 27 finished with value: 0.3098630992712667 and parameters: {'n_estimators': 600, 'max_depth': 10, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.3098630992712667.\n",
      "[I 2025-08-08 02:35:05,982] Trial 28 finished with value: 0.30888688620653143 and parameters: {'n_estimators': 400, 'max_depth': 10, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.3098630992712667.\n",
      "[I 2025-08-08 02:35:28,598] Trial 29 finished with value: 0.30179628455165397 and parameters: {'n_estimators': 200, 'max_depth': 10, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.3098630992712667.\n",
      "    ✅ 최적 XGBoost 모델 GPU(gpu_hist) 모드로 학습 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 02:35:53,732] A new study created in memory with name: no-name-541806ce-4afa-4bc1-9459-c236d4d55507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > 최종 검증 F1(weighted): 0.3108\n",
      "\n",
      "--- LightGBM 튜닝 시작 ---\n",
      "🎯 LightGBM - Duration 분류 튜닝...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e8284878f464d98a8a761cf3c61c94b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    🖥️ LightGBM GPU 모드로 실행\n",
      "[I 2025-08-08 02:37:05,177] Trial 0 finished with value: 0.7483528522640758 and parameters: {'n_estimators': 400, 'max_depth': 8, 'learning_rate': 0.03, 'num_leaves': 100}. Best is trial 0 with value: 0.7483528522640758.\n",
      "[I 2025-08-08 02:38:10,626] Trial 1 finished with value: 0.7497274558786571 and parameters: {'n_estimators': 200, 'max_depth': 10, 'learning_rate': 0.03, 'num_leaves': 200}. Best is trial 1 with value: 0.7497274558786571.\n",
      "[I 2025-08-08 02:41:18,493] Trial 2 finished with value: 0.7423721485850493 and parameters: {'n_estimators': 600, 'max_depth': 10, 'learning_rate': 0.05, 'num_leaves': 200}. Best is trial 1 with value: 0.7497274558786571.\n",
      "[I 2025-08-08 02:43:18,542] Trial 3 finished with value: 0.7371370694626286 and parameters: {'n_estimators': 600, 'max_depth': 10, 'learning_rate': 0.1, 'num_leaves': 100}. Best is trial 1 with value: 0.7497274558786571.\n",
      "[I 2025-08-08 02:43:40,333] Trial 4 finished with value: 0.7474054858757061 and parameters: {'n_estimators': 200, 'max_depth': 8, 'learning_rate': 0.05, 'num_leaves': 50}. Best is trial 1 with value: 0.7497274558786571.\n",
      "[I 2025-08-08 02:45:48,496] Trial 5 finished with value: 0.743677684818986 and parameters: {'n_estimators': 600, 'max_depth': 10, 'learning_rate': 0.05, 'num_leaves': 100}. Best is trial 1 with value: 0.7497274558786571.\n",
      "[I 2025-08-08 02:46:56,608] Trial 6 finished with value: 0.7472728381789171 and parameters: {'n_estimators': 600, 'max_depth': 8, 'learning_rate': 0.05, 'num_leaves': 50}. Best is trial 1 with value: 0.7497274558786571.\n",
      "[I 2025-08-08 02:47:40,471] Trial 7 finished with value: 0.747938004450452 and parameters: {'n_estimators': 400, 'max_depth': 8, 'learning_rate': 0.05, 'num_leaves': 50}. Best is trial 1 with value: 0.7497274558786571.\n",
      "[I 2025-08-08 02:48:13,242] Trial 8 finished with value: 0.7478384597335824 and parameters: {'n_estimators': 200, 'max_depth': 8, 'learning_rate': 0.05, 'num_leaves': 100}. Best is trial 1 with value: 0.7497274558786571.\n",
      "[I 2025-08-08 02:48:58,227] Trial 9 finished with value: 0.7443343873132907 and parameters: {'n_estimators': 400, 'max_depth': 10, 'learning_rate': 0.1, 'num_leaves': 50}. Best is trial 1 with value: 0.7497274558786571.\n",
      "[I 2025-08-08 02:50:12,172] Trial 10 finished with value: 0.7501720911448091 and parameters: {'n_estimators': 200, 'max_depth': 12, 'learning_rate': 0.03, 'num_leaves': 200}. Best is trial 10 with value: 0.7501720911448091.\n",
      "[I 2025-08-08 02:51:27,833] Trial 11 finished with value: 0.7499866193237477 and parameters: {'n_estimators': 200, 'max_depth': 12, 'learning_rate': 0.03, 'num_leaves': 200}. Best is trial 10 with value: 0.7501720911448091.\n",
      "[I 2025-08-08 02:52:45,880] Trial 12 finished with value: 0.7496369059188197 and parameters: {'n_estimators': 200, 'max_depth': 12, 'learning_rate': 0.03, 'num_leaves': 200}. Best is trial 10 with value: 0.7501720911448091.\n",
      "[I 2025-08-08 02:54:03,395] Trial 13 finished with value: 0.7495200757267959 and parameters: {'n_estimators': 200, 'max_depth': 12, 'learning_rate': 0.03, 'num_leaves': 200}. Best is trial 10 with value: 0.7501720911448091.\n",
      "[I 2025-08-08 02:55:26,479] Trial 14 finished with value: 0.7499014825527399 and parameters: {'n_estimators': 200, 'max_depth': -1, 'learning_rate': 0.03, 'num_leaves': 200}. Best is trial 10 with value: 0.7501720911448091.\n",
      "[I 2025-08-08 02:56:42,418] Trial 15 finished with value: 0.7497206030900881 and parameters: {'n_estimators': 200, 'max_depth': 12, 'learning_rate': 0.03, 'num_leaves': 200}. Best is trial 10 with value: 0.7501720911448091.\n",
      "[I 2025-08-08 02:57:59,610] Trial 16 finished with value: 0.7499784454501818 and parameters: {'n_estimators': 200, 'max_depth': 12, 'learning_rate': 0.03, 'num_leaves': 200}. Best is trial 10 with value: 0.7501720911448091.\n",
      "[I 2025-08-08 02:59:09,377] Trial 17 finished with value: 0.7440996744538376 and parameters: {'n_estimators': 200, 'max_depth': 12, 'learning_rate': 0.1, 'num_leaves': 200}. Best is trial 10 with value: 0.7501720911448091.\n",
      "[I 2025-08-08 03:01:26,743] Trial 18 finished with value: 0.7490183496139879 and parameters: {'n_estimators': 200, 'max_depth': -1, 'learning_rate': 0.03, 'num_leaves': 200}. Best is trial 10 with value: 0.7501720911448091.\n",
      "[I 2025-08-08 03:06:32,765] Trial 19 finished with value: 0.7471696816658051 and parameters: {'n_estimators': 400, 'max_depth': 12, 'learning_rate': 0.03, 'num_leaves': 200}. Best is trial 10 with value: 0.7501720911448091.\n",
      "[I 2025-08-08 03:07:46,831] Trial 20 finished with value: 0.7498045394469549 and parameters: {'n_estimators': 200, 'max_depth': 12, 'learning_rate': 0.03, 'num_leaves': 200}. Best is trial 10 with value: 0.7501720911448091.\n",
      "[I 2025-08-08 03:09:00,992] Trial 21 finished with value: 0.7501223549171024 and parameters: {'n_estimators': 200, 'max_depth': 12, 'learning_rate': 0.03, 'num_leaves': 200}. Best is trial 10 with value: 0.7501720911448091.\n",
      "[I 2025-08-08 03:10:14,916] Trial 22 finished with value: 0.7496206665833279 and parameters: {'n_estimators': 200, 'max_depth': 12, 'learning_rate': 0.03, 'num_leaves': 200}. Best is trial 10 with value: 0.7501720911448091.\n",
      "[I 2025-08-08 03:11:29,928] Trial 23 finished with value: 0.7501334984897693 and parameters: {'n_estimators': 200, 'max_depth': 12, 'learning_rate': 0.03, 'num_leaves': 200}. Best is trial 10 with value: 0.7501720911448091.\n",
      "[I 2025-08-08 03:12:47,844] Trial 24 finished with value: 0.7500478946883695 and parameters: {'n_estimators': 200, 'max_depth': 12, 'learning_rate': 0.03, 'num_leaves': 200}. Best is trial 10 with value: 0.7501720911448091.\n",
      "[I 2025-08-08 03:14:07,177] Trial 25 finished with value: 0.7419793537994938 and parameters: {'n_estimators': 200, 'max_depth': -1, 'learning_rate': 0.1, 'num_leaves': 200}. Best is trial 10 with value: 0.7501720911448091.\n",
      "[I 2025-08-08 03:15:25,560] Trial 26 finished with value: 0.7494265487834765 and parameters: {'n_estimators': 200, 'max_depth': 12, 'learning_rate': 0.03, 'num_leaves': 200}. Best is trial 10 with value: 0.7501720911448091.\n",
      "[I 2025-08-08 03:16:44,017] Trial 27 finished with value: 0.7496709437045723 and parameters: {'n_estimators': 200, 'max_depth': 12, 'learning_rate': 0.03, 'num_leaves': 200}. Best is trial 10 with value: 0.7501720911448091.\n",
      "[I 2025-08-08 03:18:57,468] Trial 28 finished with value: 0.7479308038417427 and parameters: {'n_estimators': 600, 'max_depth': 12, 'learning_rate': 0.03, 'num_leaves': 100}. Best is trial 10 with value: 0.7501720911448091.\n",
      "[I 2025-08-08 03:19:46,406] Trial 29 finished with value: 0.7472030611544308 and parameters: {'n_estimators': 400, 'max_depth': 12, 'learning_rate': 0.03, 'num_leaves': 50}. Best is trial 10 with value: 0.7501720911448091.\n",
      "    ✅ 최적 LightGBM 모델 GPU 모드로 학습 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 03:20:08,824] A new study created in memory with name: no-name-800d215e-67d5-48cb-9317-be537b402947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > 최종 검증 F1(weighted): 0.7500\n",
      "📦 LightGBM - Volume 분류 튜닝...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07a8c8d656314f7b80f0109871baf238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    🖥️ LightGBM GPU 모드로 실행\n",
      "[I 2025-08-08 03:21:11,961] Trial 0 finished with value: 0.29952613379519205 and parameters: {'n_estimators': 400, 'max_depth': 8, 'learning_rate': 0.03, 'num_leaves': 100}. Best is trial 0 with value: 0.29952613379519205.\n",
      "[I 2025-08-08 03:22:04,188] Trial 1 finished with value: 0.2960047858418456 and parameters: {'n_estimators': 200, 'max_depth': 10, 'learning_rate': 0.03, 'num_leaves': 200}. Best is trial 0 with value: 0.29952613379519205.\n",
      "[I 2025-08-08 03:24:44,092] Trial 2 finished with value: 0.3110139738558872 and parameters: {'n_estimators': 600, 'max_depth': 10, 'learning_rate': 0.05, 'num_leaves': 200}. Best is trial 2 with value: 0.3110139738558872.\n",
      "[I 2025-08-08 03:26:43,492] Trial 3 finished with value: 0.31179303336611713 and parameters: {'n_estimators': 600, 'max_depth': 10, 'learning_rate': 0.1, 'num_leaves': 100}. Best is trial 3 with value: 0.31179303336611713.\n",
      "[I 2025-08-08 03:27:03,854] Trial 4 finished with value: 0.29175511400553183 and parameters: {'n_estimators': 200, 'max_depth': 8, 'learning_rate': 0.05, 'num_leaves': 50}. Best is trial 3 with value: 0.31179303336611713.\n",
      "[I 2025-08-08 03:29:06,116] Trial 5 finished with value: 0.3091190584382056 and parameters: {'n_estimators': 600, 'max_depth': 10, 'learning_rate': 0.05, 'num_leaves': 100}. Best is trial 3 with value: 0.31179303336611713.\n",
      "[I 2025-08-08 03:30:09,515] Trial 6 finished with value: 0.3035033876714766 and parameters: {'n_estimators': 600, 'max_depth': 8, 'learning_rate': 0.05, 'num_leaves': 50}. Best is trial 3 with value: 0.31179303336611713.\n",
      "[I 2025-08-08 03:30:51,046] Trial 7 finished with value: 0.29979441519499317 and parameters: {'n_estimators': 400, 'max_depth': 8, 'learning_rate': 0.05, 'num_leaves': 50}. Best is trial 3 with value: 0.31179303336611713.\n",
      "[I 2025-08-08 03:31:19,041] Trial 8 finished with value: 0.2970733246990181 and parameters: {'n_estimators': 200, 'max_depth': 8, 'learning_rate': 0.05, 'num_leaves': 100}. Best is trial 3 with value: 0.31179303336611713.\n",
      "[I 2025-08-08 03:32:01,546] Trial 9 finished with value: 0.3065095092820365 and parameters: {'n_estimators': 400, 'max_depth': 10, 'learning_rate': 0.1, 'num_leaves': 50}. Best is trial 3 with value: 0.31179303336611713.\n",
      "[I 2025-08-08 03:34:01,550] Trial 10 finished with value: 0.3112854373279414 and parameters: {'n_estimators': 600, 'max_depth': 12, 'learning_rate': 0.1, 'num_leaves': 100}. Best is trial 3 with value: 0.31179303336611713.\n",
      "[I 2025-08-08 03:36:00,744] Trial 11 finished with value: 0.31413237037560116 and parameters: {'n_estimators': 600, 'max_depth': 12, 'learning_rate': 0.1, 'num_leaves': 100}. Best is trial 11 with value: 0.31413237037560116.\n",
      "[I 2025-08-08 03:37:58,908] Trial 12 finished with value: 0.31154541469021885 and parameters: {'n_estimators': 600, 'max_depth': 12, 'learning_rate': 0.1, 'num_leaves': 100}. Best is trial 11 with value: 0.31413237037560116.\n",
      "[I 2025-08-08 03:40:01,835] Trial 13 finished with value: 0.311079996614372 and parameters: {'n_estimators': 600, 'max_depth': -1, 'learning_rate': 0.1, 'num_leaves': 100}. Best is trial 11 with value: 0.31413237037560116.\n",
      "[I 2025-08-08 03:42:01,259] Trial 14 finished with value: 0.3125954345321607 and parameters: {'n_estimators': 600, 'max_depth': 12, 'learning_rate': 0.1, 'num_leaves': 100}. Best is trial 11 with value: 0.31413237037560116.\n",
      "[I 2025-08-08 03:44:00,845] Trial 15 finished with value: 0.31227722185857343 and parameters: {'n_estimators': 600, 'max_depth': 12, 'learning_rate': 0.1, 'num_leaves': 100}. Best is trial 11 with value: 0.31413237037560116.\n",
      "[I 2025-08-08 03:47:17,907] Trial 16 finished with value: 0.31294255917531993 and parameters: {'n_estimators': 600, 'max_depth': 12, 'learning_rate': 0.1, 'num_leaves': 200}. Best is trial 11 with value: 0.31413237037560116.\n",
      "[I 2025-08-08 03:50:33,068] Trial 17 finished with value: 0.3125393018794012 and parameters: {'n_estimators': 600, 'max_depth': 12, 'learning_rate': 0.1, 'num_leaves': 200}. Best is trial 11 with value: 0.31413237037560116.\n",
      "[I 2025-08-08 03:51:51,086] Trial 18 finished with value: 0.30053785992887905 and parameters: {'n_estimators': 200, 'max_depth': -1, 'learning_rate': 0.03, 'num_leaves': 200}. Best is trial 11 with value: 0.31413237037560116.\n",
      "[I 2025-08-08 03:53:59,922] Trial 19 finished with value: 0.3110581116597485 and parameters: {'n_estimators': 400, 'max_depth': 12, 'learning_rate': 0.1, 'num_leaves': 200}. Best is trial 11 with value: 0.31413237037560116.\n",
      "[I 2025-08-08 03:57:16,499] Trial 20 finished with value: 0.31313258592183124 and parameters: {'n_estimators': 600, 'max_depth': 12, 'learning_rate': 0.1, 'num_leaves': 200}. Best is trial 11 with value: 0.31413237037560116.\n",
      "[I 2025-08-08 04:00:33,118] Trial 21 finished with value: 0.3131579430145411 and parameters: {'n_estimators': 600, 'max_depth': 12, 'learning_rate': 0.1, 'num_leaves': 200}. Best is trial 11 with value: 0.31413237037560116.\n",
      "[I 2025-08-08 04:03:48,553] Trial 22 finished with value: 0.313981281385225 and parameters: {'n_estimators': 600, 'max_depth': 12, 'learning_rate': 0.1, 'num_leaves': 200}. Best is trial 11 with value: 0.31413237037560116.\n",
      "[I 2025-08-08 04:07:05,698] Trial 23 finished with value: 0.31125552554667363 and parameters: {'n_estimators': 600, 'max_depth': 12, 'learning_rate': 0.1, 'num_leaves': 200}. Best is trial 11 with value: 0.31413237037560116.\n",
      "[I 2025-08-08 04:10:21,993] Trial 24 finished with value: 0.3115782688502182 and parameters: {'n_estimators': 600, 'max_depth': 12, 'learning_rate': 0.1, 'num_leaves': 200}. Best is trial 11 with value: 0.31413237037560116.\n",
      "[I 2025-08-08 04:14:20,115] Trial 25 finished with value: 0.3092440966762228 and parameters: {'n_estimators': 600, 'max_depth': -1, 'learning_rate': 0.03, 'num_leaves': 200}. Best is trial 11 with value: 0.31413237037560116.\n",
      "[I 2025-08-08 04:17:34,708] Trial 26 finished with value: 0.3133431183333241 and parameters: {'n_estimators': 600, 'max_depth': 12, 'learning_rate': 0.1, 'num_leaves': 200}. Best is trial 11 with value: 0.31413237037560116.\n",
      "[I 2025-08-08 04:20:51,376] Trial 27 finished with value: 0.3125547740823314 and parameters: {'n_estimators': 600, 'max_depth': 12, 'learning_rate': 0.1, 'num_leaves': 200}. Best is trial 11 with value: 0.31413237037560116.\n",
      "[I 2025-08-08 04:21:33,881] Trial 28 finished with value: 0.30668752191547094 and parameters: {'n_estimators': 400, 'max_depth': 12, 'learning_rate': 0.1, 'num_leaves': 50}. Best is trial 11 with value: 0.31413237037560116.\n",
      "[I 2025-08-08 04:22:39,001] Trial 29 finished with value: 0.29846683182681893 and parameters: {'n_estimators': 200, 'max_depth': 12, 'learning_rate': 0.03, 'num_leaves': 200}. Best is trial 11 with value: 0.31413237037560116.\n",
      "    ✅ 최적 LightGBM 모델 GPU 모드로 학습 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 04:23:14,977] A new study created in memory with name: no-name-c105d745-6f22-42d5-9699-5dbf7cb85628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > 최종 검증 F1(weighted): 0.3083\n",
      "\n",
      "--- RandomForest 튜닝 시작 ---\n",
      "🎯 RandomForest - Duration 분류 튜닝...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "644c742b03a54320be4fc95ac67f96a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    🖥️ RandomForestClassifier CPU 멀티코어 모드로 실행\n",
      "[I 2025-08-08 04:23:23,012] Trial 0 finished with value: 0.7442127425783842 and parameters: {'n_estimators': 300, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.7442127425783842.\n",
      "[I 2025-08-08 04:23:29,895] Trial 1 finished with value: 0.7475066349609256 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.7475066349609256.\n",
      "[I 2025-08-08 04:23:39,443] Trial 2 finished with value: 0.7500187193449156 and parameters: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.7500187193449156.\n",
      "[I 2025-08-08 04:23:47,344] Trial 3 finished with value: 0.7431485453366805 and parameters: {'n_estimators': 300, 'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.7500187193449156.\n",
      "[I 2025-08-08 04:23:57,682] Trial 4 finished with value: 0.7483591912162538 and parameters: {'n_estimators': 300, 'max_depth': 25, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.7500187193449156.\n",
      "[I 2025-08-08 04:24:04,202] Trial 5 finished with value: 0.7498370779584552 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.7500187193449156.\n",
      "[I 2025-08-08 04:24:13,194] Trial 6 finished with value: 0.7496344772942479 and parameters: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.7500187193449156.\n",
      "[I 2025-08-08 04:24:22,548] Trial 7 finished with value: 0.750454297201291 and parameters: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 7 with value: 0.750454297201291.\n",
      "[I 2025-08-08 04:24:29,505] Trial 8 finished with value: 0.7478096854539169 and parameters: {'n_estimators': 200, 'max_depth': 25, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 7 with value: 0.750454297201291.\n",
      "[I 2025-08-08 04:24:36,865] Trial 9 finished with value: 0.7471950780033279 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 7 with value: 0.750454297201291.\n",
      "[I 2025-08-08 04:24:46,212] Trial 10 finished with value: 0.750454297201291 and parameters: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 7 with value: 0.750454297201291.\n",
      "[I 2025-08-08 04:24:55,592] Trial 11 finished with value: 0.750454297201291 and parameters: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 7 with value: 0.750454297201291.\n",
      "[I 2025-08-08 04:25:04,979] Trial 12 finished with value: 0.750454297201291 and parameters: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 7 with value: 0.750454297201291.\n",
      "[I 2025-08-08 04:25:14,355] Trial 13 finished with value: 0.750454297201291 and parameters: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 7 with value: 0.750454297201291.\n",
      "[I 2025-08-08 04:25:23,746] Trial 14 finished with value: 0.750454297201291 and parameters: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 7 with value: 0.750454297201291.\n",
      "[I 2025-08-08 04:25:33,159] Trial 15 finished with value: 0.750454297201291 and parameters: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 7 with value: 0.750454297201291.\n",
      "[I 2025-08-08 04:25:42,717] Trial 16 finished with value: 0.750454297201291 and parameters: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 7 with value: 0.750454297201291.\n",
      "[I 2025-08-08 04:25:50,873] Trial 17 finished with value: 0.7442127425783842 and parameters: {'n_estimators': 300, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 7 with value: 0.750454297201291.\n",
      "[I 2025-08-08 04:25:57,598] Trial 18 finished with value: 0.7498506266885078 and parameters: {'n_estimators': 200, 'max_depth': 25, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 7 with value: 0.750454297201291.\n",
      "[I 2025-08-08 04:26:06,708] Trial 19 finished with value: 0.7496344772942479 and parameters: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 7 with value: 0.750454297201291.\n",
      "[I 2025-08-08 04:26:16,198] Trial 20 finished with value: 0.750454297201291 and parameters: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 7 with value: 0.750454297201291.\n",
      "[I 2025-08-08 04:26:25,628] Trial 21 finished with value: 0.750454297201291 and parameters: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 7 with value: 0.750454297201291.\n",
      "[I 2025-08-08 04:26:35,103] Trial 22 finished with value: 0.750454297201291 and parameters: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 7 with value: 0.750454297201291.\n",
      "[I 2025-08-08 04:26:44,690] Trial 23 finished with value: 0.750454297201291 and parameters: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 7 with value: 0.750454297201291.\n",
      "[I 2025-08-08 04:26:54,200] Trial 24 finished with value: 0.750454297201291 and parameters: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 7 with value: 0.750454297201291.\n",
      "[I 2025-08-08 04:27:03,682] Trial 25 finished with value: 0.750454297201291 and parameters: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 7 with value: 0.750454297201291.\n",
      "[I 2025-08-08 04:27:10,774] Trial 26 finished with value: 0.7475066349609256 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 7 with value: 0.750454297201291.\n",
      "[I 2025-08-08 04:27:20,735] Trial 27 finished with value: 0.7495770109447507 and parameters: {'n_estimators': 300, 'max_depth': 25, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 7 with value: 0.750454297201291.\n",
      "[I 2025-08-08 04:27:29,038] Trial 28 finished with value: 0.7437073829124364 and parameters: {'n_estimators': 300, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 7 with value: 0.750454297201291.\n",
      "[I 2025-08-08 04:27:37,266] Trial 29 finished with value: 0.7431485453366805 and parameters: {'n_estimators': 300, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 7 with value: 0.750454297201291.\n",
      "    ✅ 최적 RandomForestClassifier 모델 CPU 멀티코어 모드로 학습 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 04:28:21,759] A new study created in memory with name: no-name-74a7c484-9a57-4ca8-9f66-b95c70afdc9c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > 최종 검증 F1(weighted): 0.7475\n",
      "📦 RandomForest - Volume 분류 튜닝...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6fa4385adc9449081f0a69a279fe6f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    🖥️ RandomForestClassifier CPU 멀티코어 모드로 실행\n",
      "[I 2025-08-08 04:28:31,535] Trial 0 finished with value: 0.28289182044771677 and parameters: {'n_estimators': 300, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.28289182044771677.\n",
      "[I 2025-08-08 04:28:43,870] Trial 1 finished with value: 0.31119328477861535 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.31119328477861535.\n",
      "[I 2025-08-08 04:28:56,407] Trial 2 finished with value: 0.29371532998985916 and parameters: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.31119328477861535.\n",
      "[I 2025-08-08 04:29:06,268] Trial 3 finished with value: 0.2823500800192861 and parameters: {'n_estimators': 300, 'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.31119328477861535.\n",
      "[I 2025-08-08 04:29:21,018] Trial 4 finished with value: 0.3020058468244499 and parameters: {'n_estimators': 300, 'max_depth': 25, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.31119328477861535.\n",
      "[I 2025-08-08 04:29:32,143] Trial 5 finished with value: 0.3061506071069839 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.31119328477861535.\n",
      "[I 2025-08-08 04:29:44,464] Trial 6 finished with value: 0.2915191138242818 and parameters: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.31119328477861535.\n",
      "[I 2025-08-08 04:29:57,091] Trial 7 finished with value: 0.290217650333238 and parameters: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.31119328477861535.\n",
      "[I 2025-08-08 04:30:07,190] Trial 8 finished with value: 0.3037039507671228 and parameters: {'n_estimators': 200, 'max_depth': 25, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.31119328477861535.\n",
      "[I 2025-08-08 04:30:20,129] Trial 9 finished with value: 0.3106853660858128 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.31119328477861535.\n",
      "[I 2025-08-08 04:30:32,641] Trial 10 finished with value: 0.31119328477861535 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.31119328477861535.\n",
      "[I 2025-08-08 04:30:45,234] Trial 11 finished with value: 0.31119328477861535 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.31119328477861535.\n",
      "[I 2025-08-08 04:30:57,758] Trial 12 finished with value: 0.31119328477861535 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.31119328477861535.\n",
      "[I 2025-08-08 04:31:10,438] Trial 13 finished with value: 0.31119328477861535 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.31119328477861535.\n",
      "[I 2025-08-08 04:31:22,917] Trial 14 finished with value: 0.31119328477861535 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.31119328477861535.\n",
      "[I 2025-08-08 04:31:35,464] Trial 15 finished with value: 0.31119328477861535 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.31119328477861535.\n",
      "[I 2025-08-08 04:31:48,131] Trial 16 finished with value: 0.31119328477861535 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.31119328477861535.\n",
      "[I 2025-08-08 04:31:55,104] Trial 17 finished with value: 0.2831826017799816 and parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.31119328477861535.\n",
      "[I 2025-08-08 04:32:04,955] Trial 18 finished with value: 0.29959743549791074 and parameters: {'n_estimators': 200, 'max_depth': 25, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.31119328477861535.\n",
      "[I 2025-08-08 04:32:16,256] Trial 19 finished with value: 0.3061506071069839 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.31119328477861535.\n",
      "[I 2025-08-08 04:32:28,797] Trial 20 finished with value: 0.31119328477861535 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.31119328477861535.\n",
      "[I 2025-08-08 04:32:41,507] Trial 21 finished with value: 0.31119328477861535 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.31119328477861535.\n",
      "[I 2025-08-08 04:32:54,036] Trial 22 finished with value: 0.31119328477861535 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.31119328477861535.\n",
      "[I 2025-08-08 04:33:06,593] Trial 23 finished with value: 0.31119328477861535 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.31119328477861535.\n",
      "[I 2025-08-08 04:33:19,113] Trial 24 finished with value: 0.31119328477861535 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.31119328477861535.\n",
      "[I 2025-08-08 04:33:31,707] Trial 25 finished with value: 0.31119328477861535 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.31119328477861535.\n",
      "[I 2025-08-08 04:33:38,747] Trial 26 finished with value: 0.28440330870739805 and parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.31119328477861535.\n",
      "[I 2025-08-08 04:33:48,729] Trial 27 finished with value: 0.29959743549791074 and parameters: {'n_estimators': 200, 'max_depth': 25, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.31119328477861535.\n",
      "[I 2025-08-08 04:33:57,469] Trial 28 finished with value: 0.29340478770502526 and parameters: {'n_estimators': 200, 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.31119328477861535.\n",
      "[I 2025-08-08 04:34:07,632] Trial 29 finished with value: 0.2823500800192861 and parameters: {'n_estimators': 300, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.31119328477861535.\n",
      "    ✅ 최적 RandomForestClassifier 모델 CPU 멀티코어 모드로 학습 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 04:35:03,625] A new study created in memory with name: no-name-79e2efe2-0661-4182-9b73-a2dc900efe8e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > 최종 검증 F1(weighted): 0.3137\n",
      "\n",
      "--- ExtraTrees 튜닝 시작 ---\n",
      "🎯 ExtraTrees - Duration 분류 튜닝...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ff585aa222b432ca509566af3c6e4c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    🖥️ ExtraTreesClassifier CPU 멀티코어 모드로 실행\n",
      "[I 2025-08-08 04:35:06,814] Trial 0 finished with value: 0.7142492325902485 and parameters: {'n_estimators': 300, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.7142492325902485.\n",
      "[I 2025-08-08 04:35:09,608] Trial 1 finished with value: 0.747986609992512 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.747986609992512.\n",
      "[I 2025-08-08 04:35:13,318] Trial 2 finished with value: 0.7380436013004689 and parameters: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.747986609992512.\n",
      "[I 2025-08-08 04:35:16,197] Trial 3 finished with value: 0.7110120958349491 and parameters: {'n_estimators': 300, 'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.747986609992512.\n",
      "[I 2025-08-08 04:35:20,403] Trial 4 finished with value: 0.7456201942901912 and parameters: {'n_estimators': 300, 'max_depth': 25, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.747986609992512.\n",
      "[I 2025-08-08 04:35:22,747] Trial 5 finished with value: 0.7414918904408411 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.747986609992512.\n",
      "[I 2025-08-08 04:35:26,024] Trial 6 finished with value: 0.7303228553479629 and parameters: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.747986609992512.\n",
      "[I 2025-08-08 04:35:29,368] Trial 7 finished with value: 0.7353550164203275 and parameters: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.747986609992512.\n",
      "[I 2025-08-08 04:35:32,232] Trial 8 finished with value: 0.7456238249430487 and parameters: {'n_estimators': 200, 'max_depth': 25, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.747986609992512.\n",
      "[I 2025-08-08 04:35:35,511] Trial 9 finished with value: 0.7466721654169505 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.747986609992512.\n",
      "[I 2025-08-08 04:35:38,298] Trial 10 finished with value: 0.747986609992512 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.747986609992512.\n",
      "[I 2025-08-08 04:35:40,983] Trial 11 finished with value: 0.747986609992512 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.747986609992512.\n",
      "[I 2025-08-08 04:35:43,626] Trial 12 finished with value: 0.747986609992512 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.747986609992512.\n",
      "[I 2025-08-08 04:35:46,236] Trial 13 finished with value: 0.747986609992512 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.747986609992512.\n",
      "[I 2025-08-08 04:35:48,862] Trial 14 finished with value: 0.747986609992512 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.747986609992512.\n",
      "[I 2025-08-08 04:35:51,561] Trial 15 finished with value: 0.747986609992512 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.747986609992512.\n",
      "[I 2025-08-08 04:35:54,212] Trial 16 finished with value: 0.747986609992512 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.747986609992512.\n",
      "[I 2025-08-08 04:35:56,342] Trial 17 finished with value: 0.7135720935108076 and parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.747986609992512.\n",
      "[I 2025-08-08 04:35:58,799] Trial 18 finished with value: 0.7444373853436855 and parameters: {'n_estimators': 200, 'max_depth': 25, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.747986609992512.\n",
      "[I 2025-08-08 04:36:01,115] Trial 19 finished with value: 0.7414918904408411 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.747986609992512.\n",
      "[I 2025-08-08 04:36:03,799] Trial 20 finished with value: 0.747986609992512 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.747986609992512.\n",
      "[I 2025-08-08 04:36:06,476] Trial 21 finished with value: 0.747986609992512 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.747986609992512.\n",
      "[I 2025-08-08 04:36:09,202] Trial 22 finished with value: 0.747986609992512 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.747986609992512.\n",
      "[I 2025-08-08 04:36:11,913] Trial 23 finished with value: 0.747986609992512 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.747986609992512.\n",
      "[I 2025-08-08 04:36:14,565] Trial 24 finished with value: 0.747986609992512 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.747986609992512.\n",
      "[I 2025-08-08 04:36:17,265] Trial 25 finished with value: 0.747986609992512 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.747986609992512.\n",
      "[I 2025-08-08 04:36:19,310] Trial 26 finished with value: 0.7152774493986112 and parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.747986609992512.\n",
      "[I 2025-08-08 04:36:21,840] Trial 27 finished with value: 0.7444373853436855 and parameters: {'n_estimators': 200, 'max_depth': 25, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.747986609992512.\n",
      "[I 2025-08-08 04:36:24,375] Trial 28 finished with value: 0.7380836272281194 and parameters: {'n_estimators': 200, 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.747986609992512.\n",
      "[I 2025-08-08 04:36:27,263] Trial 29 finished with value: 0.7110120958349491 and parameters: {'n_estimators': 300, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.747986609992512.\n",
      "    ✅ 최적 ExtraTreesClassifier 모델 CPU 멀티코어 모드로 학습 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 04:36:37,680] A new study created in memory with name: no-name-94c43307-2971-451b-85dd-c4446bdbea4d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > 최종 검증 F1(weighted): 0.7459\n",
      "📦 ExtraTrees - Volume 분류 튜닝...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25ed577f837c4c1fbc455f7d79deb507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    🖥️ ExtraTreesClassifier CPU 멀티코어 모드로 실행\n",
      "[I 2025-08-08 04:36:40,738] Trial 0 finished with value: 0.2760962942151801 and parameters: {'n_estimators': 300, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.2760962942151801.\n",
      "[I 2025-08-08 04:36:44,425] Trial 1 finished with value: 0.3068880949206834 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.3068880949206834.\n",
      "[I 2025-08-08 04:36:48,162] Trial 2 finished with value: 0.2882815173323199 and parameters: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.3068880949206834.\n",
      "[I 2025-08-08 04:36:51,108] Trial 3 finished with value: 0.275740437679236 and parameters: {'n_estimators': 300, 'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.3068880949206834.\n",
      "[I 2025-08-08 04:36:55,902] Trial 4 finished with value: 0.2984819932613765 and parameters: {'n_estimators': 300, 'max_depth': 25, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.3068880949206834.\n",
      "[I 2025-08-08 04:36:58,705] Trial 5 finished with value: 0.29675284199821556 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.3068880949206834.\n",
      "[I 2025-08-08 04:37:02,033] Trial 6 finished with value: 0.2858115894721616 and parameters: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.3068880949206834.\n",
      "[I 2025-08-08 04:37:05,711] Trial 7 finished with value: 0.287199693247423 and parameters: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.3068880949206834.\n",
      "[I 2025-08-08 04:37:09,089] Trial 8 finished with value: 0.2993082821846409 and parameters: {'n_estimators': 200, 'max_depth': 25, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.3068880949206834.\n",
      "[I 2025-08-08 04:37:13,982] Trial 9 finished with value: 0.31325946618238215 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 9 with value: 0.31325946618238215.\n",
      "[I 2025-08-08 04:37:18,915] Trial 10 finished with value: 0.3132918751759707 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 10 with value: 0.3132918751759707.\n",
      "[I 2025-08-08 04:37:23,717] Trial 11 finished with value: 0.31325317765542154 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 10 with value: 0.3132918751759707.\n",
      "[I 2025-08-08 04:37:28,546] Trial 12 finished with value: 0.3133328910083116 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 12 with value: 0.3133328910083116.\n",
      "[I 2025-08-08 04:37:33,445] Trial 13 finished with value: 0.3133401418502095 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 13 with value: 0.3133401418502095.\n",
      "[I 2025-08-08 04:37:38,407] Trial 14 finished with value: 0.31330325806336 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 13 with value: 0.3133401418502095.\n",
      "[I 2025-08-08 04:37:43,269] Trial 15 finished with value: 0.31330045651173116 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 13 with value: 0.3133401418502095.\n",
      "[I 2025-08-08 04:37:48,031] Trial 16 finished with value: 0.3133177284742785 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 13 with value: 0.3133401418502095.\n",
      "[I 2025-08-08 04:37:50,190] Trial 17 finished with value: 0.275225033907159 and parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 13 with value: 0.3133401418502095.\n",
      "[I 2025-08-08 04:37:52,980] Trial 18 finished with value: 0.29541676529323885 and parameters: {'n_estimators': 200, 'max_depth': 25, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 13 with value: 0.3133401418502095.\n",
      "[I 2025-08-08 04:37:55,770] Trial 19 finished with value: 0.29675284199821556 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 13 with value: 0.3133401418502095.\n",
      "[I 2025-08-08 04:38:00,557] Trial 20 finished with value: 0.31328088299295637 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 13 with value: 0.3133401418502095.\n",
      "[I 2025-08-08 04:38:05,341] Trial 21 finished with value: 0.3133027175591085 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 13 with value: 0.3133401418502095.\n",
      "[I 2025-08-08 04:38:10,166] Trial 22 finished with value: 0.3132573806806639 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 13 with value: 0.3133401418502095.\n",
      "[I 2025-08-08 04:38:14,970] Trial 23 finished with value: 0.3132971942612796 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 13 with value: 0.3133401418502095.\n",
      "[I 2025-08-08 04:38:19,866] Trial 24 finished with value: 0.3132951964204394 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 13 with value: 0.3133401418502095.\n",
      "[I 2025-08-08 04:38:24,663] Trial 25 finished with value: 0.3133030784254631 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 13 with value: 0.3133401418502095.\n",
      "[I 2025-08-08 04:38:26,871] Trial 26 finished with value: 0.2746039782659409 and parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 13 with value: 0.3133401418502095.\n",
      "[I 2025-08-08 04:38:29,906] Trial 27 finished with value: 0.2973257150719852 and parameters: {'n_estimators': 200, 'max_depth': 25, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 13 with value: 0.3133401418502095.\n",
      "[I 2025-08-08 04:38:32,281] Trial 28 finished with value: 0.2864460180107768 and parameters: {'n_estimators': 200, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 13 with value: 0.3133401418502095.\n",
      "[I 2025-08-08 04:38:35,355] Trial 29 finished with value: 0.2760962942151801 and parameters: {'n_estimators': 300, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 13 with value: 0.3133401418502095.\n",
      "    ✅ 최적 ExtraTreesClassifier 모델 CPU 멀티코어 모드로 학습 중...\n",
      "  > 최종 검증 F1(weighted): 0.3120\n",
      "\n",
      "================================================================================\n",
      "🏆 최종 성능 비교 결과\n",
      "================================================================================\n",
      "\n",
      "🎯 Duration 분류 결과 (F1-weighted 기준 정렬):\n",
      "       model  accuracy  precision  recall  f1_weighted  f1_macro\n",
      "    LightGBM    0.7470     0.7582  0.7470       0.7500    0.7818\n",
      "     XGBoost    0.7448     0.7551  0.7448       0.7476    0.7824\n",
      "RandomForest    0.7439     0.7559  0.7439       0.7475    0.7838\n",
      "  ExtraTrees    0.7438     0.7514  0.7438       0.7459    0.7711\n",
      "    CatBoost    0.7321     0.7507  0.7321       0.7365    0.7611\n",
      "\n",
      "📦 Volume 분류 결과 (F1-weighted 기준 정렬):\n",
      "       model  accuracy  precision  recall  f1_weighted  f1_macro\n",
      "RandomForest    0.3287     0.3069  0.3287       0.3137    0.2440\n",
      "  ExtraTrees    0.3156     0.3091  0.3156       0.3120    0.2532\n",
      "     XGBoost    0.3123     0.3095  0.3123       0.3108    0.2529\n",
      "    LightGBM    0.3093     0.3075  0.3093       0.3083    0.2535\n",
      "    CatBoost    0.2801     0.3033  0.2801       0.2892    0.2466\n",
      "\n",
      "🎉 전체 파이프라인 실행 완료! 🎉\n"
     ]
    }
   ],
   "source": [
    "# =======================================================\n",
    "# 🚀 4단계: 모델 튜닝 및 평가\n",
    "# =======================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"🚀 4단계: 5개 모델 100회 하이퍼파라미터 튜닝\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# --- 4-1: 환경 설정 ---\n",
    "def check_gpu_advanced():\n",
    "    gpu_status = {}\n",
    "    \n",
    "    # NVIDIA GPU 확인\n",
    "    try: \n",
    "        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, timeout=5)\n",
    "        gpu_status['nvidia'] = result.returncode == 0\n",
    "        print(f\"🔍 NVIDIA-SMI: {'✅ 감지됨' if gpu_status['nvidia'] else '❌ 미감지'}\")\n",
    "    except: \n",
    "        gpu_status['nvidia'] = False\n",
    "        print(f\"🔍 NVIDIA-SMI: ❌ 실행 실패\")\n",
    "    \n",
    "    # CatBoost GPU 테스트 (더 안전한 방식)\n",
    "    try: \n",
    "        import catboost\n",
    "        print(f\"🔍 CatBoost 버전: {catboost.__version__}\")\n",
    "        # 매우 작은 더미 데이터로 테스트\n",
    "        test_cat = CatBoostClassifier(task_type='GPU', iterations=1, verbose=False, allow_writing_files=False)\n",
    "        test_cat.fit([[1, 2], [3, 4]], [0, 1])\n",
    "        gpu_status['catboost'] = True\n",
    "        print(f\"🔍 CatBoost GPU: ✅ 작동 확인\")\n",
    "    except Exception as e:\n",
    "        gpu_status['catboost'] = False\n",
    "        print(f\"🔍 CatBoost GPU: ❌ 실패 ({str(e)[:50]}...)\")\n",
    "    \n",
    "    # XGBoost GPU 테스트 (더 안전한 방식)\n",
    "    try: \n",
    "        print(f\"🔍 XGBoost 버전: {xgb.__version__}\")\n",
    "        test_xgb = xgb.XGBClassifier(tree_method='gpu_hist', n_estimators=1, verbosity=0)\n",
    "        test_xgb.fit(np.array([[1, 2], [3, 4]]), np.array([0, 1]))\n",
    "        gpu_status['xgboost'] = True\n",
    "        print(f\"🔍 XGBoost GPU: ✅ 작동 확인\")\n",
    "    except Exception as e:\n",
    "        gpu_status['xgboost'] = False\n",
    "        print(f\"🔍 XGBoost GPU: ❌ 실패 ({str(e)[:50]}...)\")\n",
    "        # CPU 모드로 대체 테스트\n",
    "        try:\n",
    "            test_xgb_cpu = xgb.XGBClassifier(tree_method='hist', n_estimators=1, verbosity=0)\n",
    "            test_xgb_cpu.fit(np.array([[1, 2], [3, 4]]), np.array([0, 1]))\n",
    "            print(f\"🔍 XGBoost CPU: ✅ CPU 모드는 정상\")\n",
    "        except:\n",
    "            print(f\"🔍 XGBoost CPU: ❌ CPU 모드도 실패\")\n",
    "    \n",
    "    # LightGBM GPU 테스트 (더 안전한 방식)\n",
    "    try: \n",
    "        print(f\"🔍 LightGBM 버전: {lgb.__version__}\")\n",
    "        test_lgb = lgb.LGBMClassifier(device='gpu', n_estimators=1, verbose=-1, force_row_wise=True)\n",
    "        test_lgb.fit([[1, 2], [3, 4]], [0, 1])\n",
    "        gpu_status['lightgbm'] = True\n",
    "        print(f\"🔍 LightGBM GPU: ✅ 작동 확인\")\n",
    "    except Exception as e:\n",
    "        gpu_status['lightgbm'] = False\n",
    "        print(f\"🔍 LightGBM GPU: ❌ 실패 ({str(e)[:50]}...)\")\n",
    "        # CPU 모드로 대체 테스트\n",
    "        try:\n",
    "            test_lgb_cpu = lgb.LGBMClassifier(device='cpu', n_estimators=1, verbose=-1)\n",
    "            test_lgb_cpu.fit([[1, 2], [3, 4]], [0, 1])\n",
    "            print(f\"🔍 LightGBM CPU: ✅ CPU 모드는 정상\")\n",
    "        except:\n",
    "            print(f\"🔍 LightGBM CPU: ❌ CPU 모드도 실패\")\n",
    "    \n",
    "    return gpu_status\n",
    "\n",
    "gpu_status = check_gpu_advanced()\n",
    "print(f\"🖥️ GPU 상태: NVIDIA {'✅' if gpu_status['nvidia'] else '❌'} | CatBoost {'✅' if gpu_status['catboost'] else '❌'} | XGBoost {'✅' if gpu_status['xgboost'] else '❌'} | LightGBM {'✅' if gpu_status['lightgbm'] else '❌'}\")\n",
    "if not OPTUNA_AVAILABLE:\n",
    "    print(\"❌ Optuna 없음 - 랜덤 서치로 대체합니다. (pip install optuna 권장)\")\n",
    "\n",
    "# --- 4-2: 데이터 분할 및 가중치 계산 ---\n",
    "X = advanced_features_df\n",
    "y_duration = valid_flow_data['duration_class']\n",
    "y_volume = valid_flow_data['volume_class']\n",
    "X_train, X_test, y_duration_train, y_duration_test = train_test_split(X, y_duration, test_size=0.2, random_state=42, stratify=y_duration)\n",
    "_, _, y_volume_train, y_volume_test = train_test_split(X, y_volume, test_size=0.2, random_state=42, stratify=y_volume)\n",
    "print(f\"\\n📊 데이터 준비: 학습 {X_train.shape[0]:,}개 | 검증 {X_test.shape[0]:,}개 | 특징 {X_train.shape[1]:,}개\")\n",
    "\n",
    "duration_classes = np.unique(y_duration_train); duration_weights = compute_class_weight('balanced', classes=duration_classes, y=y_duration_train)\n",
    "duration_class_weights = {int(cls): weight for cls, weight in zip(duration_classes, duration_weights)}\n",
    "volume_classes = np.unique(y_volume_train); volume_weights = compute_class_weight('balanced', classes=volume_classes, y=y_volume_train)\n",
    "volume_class_weights = {int(cls): weight for cls, weight in zip(volume_classes, volume_weights)}\n",
    "print(f\"⚖️ 클래스 가중치 계산 완료\")\n",
    "\n",
    "# --- 4-3: Optuna 튜닝 클래스 정의 ---\n",
    "results = {'model': [], 'task': [], 'accuracy': [], 'precision': [], 'recall': [], 'f1_weighted': [], 'f1_macro': []}\n",
    "def evaluate_model(model, X_test, y_test, model_name, task_name):\n",
    "    y_pred = model.predict(X_test)\n",
    "    f1_w = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    results['model'].append(model_name); results['task'].append(task_name)\n",
    "    results['accuracy'].append(accuracy_score(y_test, y_pred)); results['precision'].append(precision_score(y_test, y_pred, average='weighted', zero_division=0))\n",
    "    results['recall'].append(recall_score(y_test, y_pred, average='weighted', zero_division=0)); results['f1_weighted'].append(f1_w)\n",
    "    results['f1_macro'].append(f1_score(y_test, y_pred, average='macro', zero_division=0))\n",
    "    print(f\"  > 최종 검증 F1(weighted): {f1_w:.4f}\")\n",
    "\n",
    "class OptunaHyperparameterSearch:\n",
    "    def __init__(self, model_class, param_space, n_trials=100, cv=3, random_state=42, use_gpu=False):\n",
    "        self.model_class, self.param_space, self.n_trials, self.cv, self.random_state, self.use_gpu = model_class, param_space, n_trials, cv, random_state, use_gpu\n",
    "        self.best_params_, self.best_estimator_ = None, None\n",
    "\n",
    "    def objective(self, trial):\n",
    "        params = {name: trial.suggest_categorical(name, values) for name, values in self.param_space.items()}\n",
    "        model_params = {'random_state': self.random_state}\n",
    "        \n",
    "        # 모델별 GPU 설정 및 확인 메시지\n",
    "        if self.model_class.__name__ == 'CatBoostClassifier': \n",
    "            model_params.update({\n",
    "                'task_type': 'GPU' if self.use_gpu else 'CPU', \n",
    "                'verbose': False,\n",
    "                'allow_writing_files': False\n",
    "            })\n",
    "            if trial.number == 0:  # 첫 번째 시도에서만 출력\n",
    "                print(f\"    🖥️ CatBoost {'GPU' if self.use_gpu else 'CPU'} 모드로 실행\")\n",
    "                \n",
    "        elif self.model_class.__name__ == 'XGBClassifier': \n",
    "            model_params.update({\n",
    "                'tree_method': 'gpu_hist' if self.use_gpu else 'hist', \n",
    "                'eval_metric': 'mlogloss', \n",
    "                'n_jobs': -1 if not self.use_gpu else 1,\n",
    "                'verbosity': 1 if self.use_gpu and trial.number == 0 else 0  # GPU 첫 시도만 verbose\n",
    "            })\n",
    "            if trial.number == 0:\n",
    "                print(f\"    🖥️ XGBoost {'GPU(gpu_hist)' if self.use_gpu else 'CPU(hist)'} 모드로 실행\")\n",
    "                \n",
    "        elif self.model_class.__name__ == 'LGBMClassifier': \n",
    "            model_params.update({\n",
    "                'device': 'gpu' if self.use_gpu else 'cpu', \n",
    "                'verbose': -1, \n",
    "                'n_jobs': -1 if not self.use_gpu else 1,\n",
    "                'force_row_wise': True if self.use_gpu else False\n",
    "            })\n",
    "            if trial.number == 0:\n",
    "                print(f\"    🖥️ LightGBM {'GPU' if self.use_gpu else 'CPU'} 모드로 실행\")\n",
    "                \n",
    "        elif self.model_class.__name__ in ['RandomForestClassifier', 'ExtraTreesClassifier']: \n",
    "            model_params.update({'n_jobs': -1})\n",
    "            if trial.number == 0:\n",
    "                print(f\"    🖥️ {self.model_class.__name__} CPU 멀티코어 모드로 실행\")\n",
    "        \n",
    "        model = self.model_class(**{**model_params, **params})\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=self.cv, shuffle=True, random_state=self.random_state)\n",
    "        scores = []\n",
    "        for train_idx, val_idx in skf.split(self.X, self.y):\n",
    "            X_train_fold, y_train_fold = self.X.iloc[train_idx], self.y.iloc[train_idx]\n",
    "            X_val_fold, y_val_fold = self.X.iloc[val_idx], self.y.iloc[val_idx]\n",
    "            \n",
    "            fit_params = {}\n",
    "            if self.class_weights and self.model_class.__name__ == 'XGBClassifier':\n",
    "                fit_params['sample_weight'] = np.array([self.class_weights[cls] for cls in y_train_fold])\n",
    "            \n",
    "            model.fit(X_train_fold, y_train_fold, **fit_params)\n",
    "            scores.append(f1_score(y_val_fold, model.predict(X_val_fold), average='weighted', zero_division=0))\n",
    "        return np.mean(scores)\n",
    "    \n",
    "    def fit(self, X, y, class_weights=None):\n",
    "        self.X, self.y, self.class_weights = X, y, class_weights\n",
    "        \n",
    "        if OPTUNA_AVAILABLE:\n",
    "            study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=self.random_state))\n",
    "            study.optimize(self.objective, n_trials=self.n_trials, show_progress_bar=True)\n",
    "            self.best_params_ = study.best_params\n",
    "        else: # Optuna 미설치 시 랜덤 파라미터 1개로만 테스트\n",
    "            self.best_params_ = {name: values[0] for name, values in self.param_space.items()}\n",
    "\n",
    "        # 최적 모델 생성 시에도 GPU 사용 확인\n",
    "        model_params = {'random_state': self.random_state, **self.best_params_}\n",
    "        if self.model_class.__name__ == 'CatBoostClassifier': \n",
    "            model_params.update({\n",
    "                'task_type': 'GPU' if self.use_gpu else 'CPU', \n",
    "                'verbose': False, \n",
    "                'class_weights': self.class_weights,\n",
    "                'allow_writing_files': False\n",
    "            })\n",
    "            print(f\"    ✅ 최적 CatBoost 모델 {'GPU' if self.use_gpu else 'CPU'} 모드로 학습 중...\")\n",
    "            \n",
    "        elif self.model_class.__name__ == 'LGBMClassifier' or self.model_class.__name__ in ['RandomForestClassifier', 'ExtraTreesClassifier']: \n",
    "            model_params.update({'class_weight': 'balanced'})\n",
    "            if self.model_class.__name__ == 'LGBMClassifier':\n",
    "                model_params.update({\n",
    "                    'device': 'gpu' if self.use_gpu else 'cpu',\n",
    "                    'verbose': -1,\n",
    "                    'force_row_wise': True if self.use_gpu else False\n",
    "                })\n",
    "                print(f\"    ✅ 최적 LightGBM 모델 {'GPU' if self.use_gpu else 'CPU'} 모드로 학습 중...\")\n",
    "            else:\n",
    "                print(f\"    ✅ 최적 {self.model_class.__name__} 모델 CPU 멀티코어 모드로 학습 중...\")\n",
    "        \n",
    "        elif self.model_class.__name__ == 'XGBClassifier':\n",
    "            model_params.update({\n",
    "                'tree_method': 'gpu_hist' if self.use_gpu else 'hist',\n",
    "                'eval_metric': 'mlogloss',\n",
    "                'n_jobs': -1 if not self.use_gpu else 1\n",
    "            })\n",
    "            print(f\"    ✅ 최적 XGBoost 모델 {'GPU(gpu_hist)' if self.use_gpu else 'CPU(hist)'} 모드로 학습 중...\")\n",
    "        \n",
    "        self.best_estimator_ = self.model_class(**model_params)\n",
    "        \n",
    "        fit_params = {}\n",
    "        if self.class_weights and self.model_class.__name__ == 'XGBClassifier':\n",
    "            fit_params['sample_weight'] = np.array([self.class_weights[cls] for cls in y])\n",
    "\n",
    "        self.best_estimator_.fit(X, y, **fit_params)\n",
    "        return self\n",
    "\n",
    "# --- 4-4: 모델별 튜닝 실행 ---\n",
    "param_spaces = {\n",
    "    'CatBoost': {'iterations': [200, 400, 600], 'depth': [6, 8, 10, 12], 'learning_rate': [0.03, 0.05, 0.1], 'l2_leaf_reg': [3, 5, 7], 'border_count': [128, 254]},\n",
    "    'XGBoost': {'n_estimators': [200, 400, 600], 'max_depth': [6, 8, 10], 'learning_rate': [0.03, 0.05, 0.1], 'subsample': [0.8, 0.9], 'colsample_bytree': [0.8, 0.9]},\n",
    "    'LightGBM': {'n_estimators': [200, 400, 600], 'max_depth': [8, 10, 12, -1], 'learning_rate': [0.03, 0.05, 0.1], 'num_leaves': [50, 100, 200]},\n",
    "    'RandomForest': {'n_estimators': [200, 300], 'max_depth': [15, 20, 25, None], 'min_samples_split': [2, 5], 'min_samples_leaf': [1, 2, 4]},\n",
    "    'ExtraTrees': {'n_estimators': [200, 300], 'max_depth': [15, 20, 25, None], 'min_samples_split': [2, 5], 'min_samples_leaf': [1, 2, 4]}\n",
    "}\n",
    "models_to_tune = [\n",
    "    (CatBoostClassifier, 'CatBoost', gpu_status['catboost']),\n",
    "    (xgb.XGBClassifier, 'XGBoost', gpu_status['xgboost']),\n",
    "    (lgb.LGBMClassifier, 'LightGBM', gpu_status['lightgbm']),\n",
    "    (RandomForestClassifier, 'RandomForest', False),\n",
    "    (ExtraTreesClassifier, 'ExtraTrees', False)\n",
    "]\n",
    "\n",
    "for model_class, name, use_gpu in models_to_tune:\n",
    "    print(f\"\\n--- {name} 튜닝 시작 ---\")\n",
    "    # Duration 분류\n",
    "    print(f\"🎯 {name} - Duration 분류 튜닝...\")\n",
    "    search_duration = OptunaHyperparameterSearch(model_class, param_spaces[name], n_trials=30, use_gpu=use_gpu).fit(X_train, y_duration_train, class_weights=duration_class_weights if name == 'CatBoost' or name == 'XGBoost' else None)\n",
    "    evaluate_model(search_duration.best_estimator_, X_test, y_duration_test, name, 'Duration')\n",
    "    \n",
    "    # Volume 분류\n",
    "    print(f\"📦 {name} - Volume 분류 튜닝...\")\n",
    "    search_volume = OptunaHyperparameterSearch(model_class, param_spaces[name], n_trials=30, use_gpu=use_gpu).fit(X_train, y_volume_train, class_weights=volume_class_weights if name == 'CatBoost' or name == 'XGBoost' else None)\n",
    "    evaluate_model(search_volume.best_estimator_, X_test, y_volume_test, name, 'Volume')\n",
    "\n",
    "# =======================================================\n",
    "# 🏆 5단계: 최종 성능 비교 결과\n",
    "# =======================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"🏆 최종 성능 비교 결과\")\n",
    "print(\"=\"*80)\n",
    "final_results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"\\n🎯 Duration 분류 결과 (F1-weighted 기준 정렬):\")\n",
    "duration_results = final_results_df[final_results_df['task'] == 'Duration'].sort_values('f1_weighted', ascending=False)\n",
    "print(duration_results[['model', 'accuracy', 'precision', 'recall', 'f1_weighted', 'f1_macro']].round(4).to_string(index=False))\n",
    "\n",
    "print(\"\\n📦 Volume 분류 결과 (F1-weighted 기준 정렬):\")\n",
    "volume_results = final_results_df[final_results_df['task'] == 'Volume'].sort_values('f1_weighted', ascending=False)\n",
    "print(volume_results[['model', 'accuracy', 'precision', 'recall', 'f1_weighted', 'f1_macro']].round(4).to_string(index=False))\n",
    "\n",
    "print(\"\\n🎉 전체 파이프라인 실행 완료! 🎉\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c15abf8",
   "metadata": {},
   "source": [
    "[I 2025-08-08 02:05:16,485] Trial 19 finished with value: 0.747744586489528 and parameters: {'n_estimators': 400, 'max_depth': 10, 'learning_rate': 0.03, 'subsample': 0.8, 'colsample_bytree': 0.8}. Best is trial 19 with value: 0.747744586489528. 이게 xg,[I 2025-08-08 02:50:12,172] Trial 10 finished with value: 0.7501720911448091 and parameters: {'n_estimators': 200, 'max_depth': 12, 'learning_rate': 0.03, 'num_leaves': 200}. Best is trial 10 with value: 0.7501720911448091.이게 light,[I 2025-08-08 04:24:22,548] Trial 7 finished with value: 0.750454297201291 and parameters: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 7 with value: 0.750454297201291.이게 랜덤포레스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0427af11",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Duration 분류 모델 학습\u001b[39;00m\n\u001b[32m     23\u001b[39m lgb_duration = lgb.LGBMClassifier(**lgb_best_params)\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m lgb_duration.fit(\u001b[43mX_train\u001b[49m, y_duration_train)\n\u001b[32m     25\u001b[39m joblib.dump(lgb_duration, \u001b[33m'\u001b[39m\u001b[33mmodel/lgb_duration_model.pkl\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     26\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m✅ LightGBM Duration 모델 저장 완료: model/lgb_duration_model.pkl\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# LightGBM 튜닝된 값으로 모델 학습 및 저장\n",
    "import joblib\n",
    "\n",
    "# gpu_status가 정의되어 있지 않으면 CPU로 강제 지정\n",
    "try:\n",
    "    _gpu_status = gpu_status\n",
    "except NameError:\n",
    "    gpu_status = {'lightgbm': False}\n",
    "\n",
    "# 예시: 튜닝된 best_params를 직접 입력 (실제 튜닝 결과에 맞게 수정)\n",
    "lgb_best_params = {\n",
    "    'n_estimators': 200,\n",
    "    'max_depth': 12,\n",
    "    'learning_rate': 0.03,\n",
    "    'num_leaves': 200,\n",
    "    'device': 'gpu' if gpu_status.get('lightgbm', False) else 'cpu',\n",
    "    'verbose': -1,\n",
    "    'force_row_wise': True if gpu_status.get('lightgbm', False) else False,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "# Duration 분류 모델 학습\n",
    "lgb_duration = lgb.LGBMClassifier(**lgb_best_params)\n",
    "lgb_duration.fit(X_train, y_duration_train)\n",
    "joblib.dump(lgb_duration, 'model/lgb_duration_model.pkl')\n",
    "print('✅ LightGBM Duration 모델 저장 완료: model/lgb_duration_model.pkl')\n",
    "\n",
    "# Volume 분류 모델 학습\n",
    "lgb_volume = lgb.LGBMClassifier(**lgb_best_params)\n",
    "lgb_volume.fit(X_train, y_volume_train)\n",
    "joblib.dump(lgb_volume, 'model/lgb_volume_model.pkl')\n",
    "print('✅ LightGBM Volume 모델 저장 완료: model/lgb_volume_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
